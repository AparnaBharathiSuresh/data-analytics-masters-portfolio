{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf65d2a9-c9d8-4a3c-a5a5-5e1634a13eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: trl in /opt/conda/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.8.5)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: bert_score in /opt/conda/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (4.1.0)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.45.5)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.15.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.11.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.5.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (2.2.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.15.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (3.2.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets peft trl transformers pandas torch spacy nltk rouge_score bert_score sentence_transformers bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "943fb053-9de5-472f-a6fd-aae16b7f6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, PeftModelForCausalLM\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TrainerCallback\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4d1009f-873c-4906-a9e5-07cfc9c0cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(instruction, input_text):\n",
    "    \"\"\"Format the instruction and input into a prompt\"\"\"\n",
    "    if input_text:\n",
    "        return f\"{instruction}\\n\\n{input_text}\"\n",
    "    return instruction\n",
    "\n",
    "def load_and_format_dataset(file_path, train_split=0.8, output_dir=\"data\"):\n",
    "    \"\"\"Improved dataset preparation\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Validate and filter\n",
    "    required_columns = [\"instruction\", \"input\", \"output\"]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Dataset must contain {required_columns} columns\")\n",
    "    df = df[df[\"input\"] != \"No structured clinical data available.\"]\n",
    "\n",
    "    formatted_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Create chat format\n",
    "        user_msg = create_prompt(row[\"instruction\"], row[\"input\"])\n",
    "        assistant_msg = row[\"output\"]\n",
    "\n",
    "        # Create both formats\n",
    "        formatted_data.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": user_msg},\n",
    "                {\"role\": \"assistant\", \"content\": assistant_msg}\n",
    "            ],\n",
    "            \"text\": f\"### User: {user_msg} ###\\n### Assistant: {assistant_msg} ###\"\n",
    "        })\n",
    "\n",
    "    # Split and save\n",
    "    train_size = int(len(formatted_data) * train_split)\n",
    "    for split, data in [(\"train\", formatted_data[:train_size]),\n",
    "                       (\"validation\", formatted_data[train_size:])]:\n",
    "        with open(os.path.join(output_dir, f\"{split}.jsonl\"), \"w\") as f:\n",
    "            for item in data:\n",
    "                json.dump(item, f)\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Saved {train_size} training and {len(formatted_data)-train_size} validation examples\")\n",
    "    return load_dataset(\"json\", data_files={\n",
    "        \"train\": os.path.join(output_dir, \"train.jsonl\"),\n",
    "        \"validation\": os.path.join(output_dir, \"validation.jsonl\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1fbbbc2-616e-430e-a6da-842e8b3ba33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_dataset(dataset, tokenizer, output_dir=\"preprocessed_data\"):\n",
    "    \"\"\"Pre-tokenize and cache dataset\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    def tokenize_function(example):\n",
    "        return tokenizer(example[\"text\"], truncation=True, max_length=512)  # Truncate to 512 tokens\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"messages\", \"text\"])\n",
    "    tokenized_dataset.save_to_disk(output_dir)\n",
    "    return tokenized_dataset\n",
    "\n",
    "def configure_qlora_model(model_name=\"BioMistral/BioMistral-7B\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "        llm_int8_enable_fp32_cpu_offload=True,\n",
    "        llm_int8_skip_modules=[\"lm_head\"]\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True,\n",
    "        offload_folder=\"offload\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        offload_state_dict=True\n",
    "    )\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=4,  # Reduced from 8\n",
    "        lora_alpha=8,  # Reduced from 16\n",
    "        lora_dropout=0.05,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        inference_mode=False,\n",
    "        fan_in_fan_out=False,\n",
    "        modules_to_save=[\"embed_tokens\", \"lm_head\"]\n",
    "    )\n",
    "\n",
    "    print(\"Applying PEFT adapters to the model...\")\n",
    "    peft_model = get_peft_model(model, lora_config)\n",
    "    print(f\"[DEBUG] Type after get_peft_model: {type(peft_model)}\")\n",
    "\n",
    "    if not isinstance(peft_model, (PeftModel, PeftModelForCausalLM)):\n",
    "        raise ValueError(\"Model is not a PEFT model instance!\")\n",
    "    else:\n",
    "        print(\"[OK] Model wrapped with PEFT successfully.\")\n",
    "\n",
    "    print(peft_model.print_trainable_parameters())\n",
    "\n",
    "    for name, param in peft_model.named_parameters():\n",
    "        if 'lora' in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return peft_model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3897ae90-7d4b-4ba1-acb1-bd405582debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing dataset...\n",
      "Saved 89530 training and 22383 validation examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 89530 examples [00:00, 127067.52 examples/s]\n",
      "Generating validation split: 22383 examples [00:00, 70543.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages', 'text'],\n",
      "        num_rows: 89530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['messages', 'text'],\n",
      "        num_rows: 22383\n",
      "    })\n",
      "})\n",
      "Preprocessing and tokenizing dataset...\n",
      "Applying PEFT adapters to the model...\n",
      "[DEBUG] Type after get_peft_model: <class 'peft.peft_model.PeftModelForCausalLM'>\n",
      "[OK] Model wrapped with PEFT successfully.\n",
      "trainable params: 263,847,936 || all params: 7,505,580,032 || trainable%: 3.5154\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 89530/89530 [00:06<00:00, 14732.64 examples/s]\n",
      "Map: 100%|██████████| 22383/22383 [00:02<00:00, 10456.00 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 89530/89530 [00:00<00:00, 194837.54 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 22383/22383 [00:00<00:00, 136320.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 89530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 22383\n",
      "    })\n",
      "})\n",
      "Configuring QLoRA model...\n",
      "Applying PEFT adapters to the model...\n",
      "[DEBUG] Type after get_peft_model: <class 'peft.peft_model.PeftModelForCausalLM'>\n",
      "[OK] Model wrapped with PEFT successfully.\n",
      "trainable params: 263,847,936 || all params: 7,505,580,032 || trainable%: 3.5154\n",
      "None\n",
      "QLoRA model configured successfully!\n",
      "Setting up trainer...\n",
      "Model is a PEFT model: True\n",
      "Creating SFTTrainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:502: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a formatting function. Therefore `formatting_func` will be ignored. Either remove the `formatting_func` or pass a dataset that is not already processed.\n",
      "  warnings.warn(\n",
      "Truncating train dataset: 100%|██████████| 89530/89530 [00:00<00:00, 898271.32 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 22383/22383 [00:00<00:00, 536564.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer configured successfully!\n",
      "Starting training...\n",
      "{'loss': 1.6351, 'grad_norm': 7.283622741699219, 'learning_rate': 9.900793650793653e-06, 'num_tokens': 940112.0, 'mean_token_accuracy': 0.6421667729467153, 'epoch': 0.044677761644141625}\n",
      "{'loss': 1.1773, 'grad_norm': 5.173727035522461, 'learning_rate': 1.9821428571428575e-05, 'num_tokens': 1877137.0, 'mean_token_accuracy': 0.7194705040603876, 'epoch': 0.08935552328828325}\n",
      "{'loss': 1.1184, 'grad_norm': 5.989350318908691, 'learning_rate': 1.9988783706475986e-05, 'num_tokens': 2815392.0, 'mean_token_accuracy': 0.7302952159643173, 'epoch': 0.1340332849324249}\n",
      "{'loss': 1.0983, 'grad_norm': 4.816073894500732, 'learning_rate': 1.9954334934823527e-05, 'num_tokens': 3762059.0, 'mean_token_accuracy': 0.7342264630496502, 'epoch': 0.1787110465765665}\n",
      "{'loss': 1.0681, 'grad_norm': 4.949990272521973, 'learning_rate': 1.9896730051713873e-05, 'num_tokens': 4716272.0, 'mean_token_accuracy': 0.7409440707862377, 'epoch': 0.22338880822070814}\n",
      "{'loss': 1.0547, 'grad_norm': 4.311347007751465, 'learning_rate': 1.9816103059579382e-05, 'num_tokens': 5664038.0, 'mean_token_accuracy': 0.7440310632884503, 'epoch': 0.2680665698648498}\n",
      "{'loss': 1.0313, 'grad_norm': 5.035603046417236, 'learning_rate': 1.9712641515663064e-05, 'num_tokens': 6604183.0, 'mean_token_accuracy': 0.7486290935128928, 'epoch': 0.3127443315089914}\n",
      "{'loss': 1.0099, 'grad_norm': 4.630031585693359, 'learning_rate': 1.9586586095716547e-05, 'num_tokens': 7543462.0, 'mean_token_accuracy': 0.7529006230384111, 'epoch': 0.357422093153133}\n",
      "{'loss': 0.9946, 'grad_norm': 4.8410491943359375, 'learning_rate': 1.9438230034132008e-05, 'num_tokens': 8481330.0, 'mean_token_accuracy': 0.7564526641517878, 'epoch': 0.40209985479727467}\n",
      "{'loss': 0.9902, 'grad_norm': 5.015018463134766, 'learning_rate': 1.9267918441810357e-05, 'num_tokens': 9424882.0, 'mean_token_accuracy': 0.75703254327178, 'epoch': 0.4467776164414163}\n",
      "{'loss': 1.0111, 'grad_norm': 4.3631439208984375, 'learning_rate': 1.907604750335259e-05, 'num_tokens': 10379046.0, 'mean_token_accuracy': 0.753615432024002, 'epoch': 0.4914553780855579}\n",
      "{'loss': 1.0004, 'grad_norm': 4.326626777648926, 'learning_rate': 1.8863063555441704e-05, 'num_tokens': 11329464.0, 'mean_token_accuracy': 0.7568447121977806, 'epoch': 0.5361331397296996}\n",
      "{'loss': 0.9808, 'grad_norm': 5.027261257171631, 'learning_rate': 1.8629462048559194e-05, 'num_tokens': 12282056.0, 'mean_token_accuracy': 0.7594540525376797, 'epoch': 0.5808109013738412}\n",
      "{'loss': 0.9683, 'grad_norm': 4.900219917297363, 'learning_rate': 1.8375786394451344e-05, 'num_tokens': 13234355.0, 'mean_token_accuracy': 0.7617816539108753, 'epoch': 0.6254886630179828}\n",
      "{'loss': 0.9578, 'grad_norm': 3.4661877155303955, 'learning_rate': 1.810262670202637e-05, 'num_tokens': 14169571.0, 'mean_token_accuracy': 0.7639194100797176, 'epoch': 0.6701664246621244}\n",
      "{'loss': 0.9556, 'grad_norm': 4.794049263000488, 'learning_rate': 1.78106184046231e-05, 'num_tokens': 15104374.0, 'mean_token_accuracy': 0.7661216255277395, 'epoch': 0.714844186306266}\n",
      "{'loss': 0.9397, 'grad_norm': 3.4183247089385986, 'learning_rate': 1.7500440781844376e-05, 'num_tokens': 16038632.0, 'mean_token_accuracy': 0.7688782845884562, 'epoch': 0.7595219479504077}\n",
      "{'loss': 0.937, 'grad_norm': 4.0547919273376465, 'learning_rate': 1.717281537939382e-05, 'num_tokens': 16979226.0, 'mean_token_accuracy': 0.7710898879766465, 'epoch': 0.8041997095945493}\n",
      "{'loss': 0.9284, 'grad_norm': 4.951482772827148, 'learning_rate': 1.6828504330591732e-05, 'num_tokens': 17923959.0, 'mean_token_accuracy': 0.7731205052882433, 'epoch': 0.848877471238691}\n",
      "{'loss': 0.9247, 'grad_norm': 4.380518913269043, 'learning_rate': 1.646830858347475e-05, 'num_tokens': 18866246.0, 'mean_token_accuracy': 0.7741364935040473, 'epoch': 0.8935552328828326}\n",
      "{'loss': 0.9381, 'grad_norm': 4.772268772125244, 'learning_rate': 1.6093066037603344e-05, 'num_tokens': 19813696.0, 'mean_token_accuracy': 0.7709584816247225, 'epoch': 0.9382329945269742}\n",
      "{'loss': 0.9139, 'grad_norm': 4.251375675201416, 'learning_rate': 1.5703649594911443e-05, 'num_tokens': 20749283.0, 'mean_token_accuracy': 0.7764911170601845, 'epoch': 0.9829107561711158}\n",
      "{'eval_loss': 1.8135493993759155, 'eval_runtime': 3566.3832, 'eval_samples_per_second': 6.276, 'eval_steps_per_second': 6.276, 'eval_num_tokens': 21110742.0, 'eval_mean_token_accuracy': 0.572996938206771, 'epoch': 1.0}\n",
      "{'loss': 0.848, 'grad_norm': 3.8094677925109863, 'learning_rate': 1.5300965129132384e-05, 'num_tokens': 21689051.0, 'mean_token_accuracy': 0.7888461225887627, 'epoch': 1.0275215011727912}\n",
      "{'loss': 0.8245, 'grad_norm': 3.764472246170044, 'learning_rate': 1.48859493785247e-05, 'num_tokens': 22630932.0, 'mean_token_accuracy': 0.7926636889576912, 'epoch': 1.0721992628169328}\n",
      "{'loss': 0.8113, 'grad_norm': 4.780592918395996, 'learning_rate': 1.445956776679981e-05, 'num_tokens': 23578321.0, 'mean_token_accuracy': 0.7947837253212928, 'epoch': 1.1168770244610744}\n",
      "{'loss': 0.8089, 'grad_norm': 5.224052429199219, 'learning_rate': 1.4022812157320673e-05, 'num_tokens': 24517733.0, 'mean_token_accuracy': 0.7958809475302696, 'epoch': 1.1615547861052162}\n",
      "{'loss': 0.8051, 'grad_norm': 4.979113578796387, 'learning_rate': 1.3576698545795572e-05, 'num_tokens': 25460103.0, 'mean_token_accuracy': 0.798146735727787, 'epoch': 1.2062325477493578}\n",
      "{'loss': 0.7913, 'grad_norm': 6.564523220062256, 'learning_rate': 1.3122264696834468e-05, 'num_tokens': 26403045.0, 'mean_token_accuracy': 0.8011780894398689, 'epoch': 1.2509103093934995}\n",
      "{'loss': 0.804, 'grad_norm': 3.743936777114868, 'learning_rate': 1.2660567729865772e-05, 'num_tokens': 27338839.0, 'mean_token_accuracy': 0.7991109745800495, 'epoch': 1.295588071037641}\n",
      "{'loss': 0.8096, 'grad_norm': 6.153774738311768, 'learning_rate': 1.2192681660029271e-05, 'num_tokens': 28283157.0, 'mean_token_accuracy': 0.7987765783816576, 'epoch': 1.3402658326817827}\n",
      "{'loss': 0.797, 'grad_norm': 4.426479339599609, 'learning_rate': 1.171969489976571e-05, 'num_tokens': 29220337.0, 'mean_token_accuracy': 0.8016723594069481, 'epoch': 1.3849435943259243}\n",
      "{'loss': 0.7856, 'grad_norm': 5.226786136627197, 'learning_rate': 1.1242707726914864e-05, 'num_tokens': 30167131.0, 'mean_token_accuracy': 0.805800045132637, 'epoch': 1.429621355970066}\n",
      "{'loss': 0.8104, 'grad_norm': 5.986502170562744, 'learning_rate': 1.0762829725211909e-05, 'num_tokens': 31121070.0, 'mean_token_accuracy': 0.8012162229716778, 'epoch': 1.4742991176142075}\n",
      "{'loss': 0.8008, 'grad_norm': 3.5858895778656006, 'learning_rate': 1.0281177203136117e-05, 'num_tokens': 32072103.0, 'mean_token_accuracy': 0.8041394616663456, 'epoch': 1.5189768792583491}\n",
      "{'loss': 0.7819, 'grad_norm': 5.0719757080078125, 'learning_rate': 9.798870597116227e-06, 'num_tokens': 33012986.0, 'mean_token_accuracy': 0.8073732586950064, 'epoch': 1.5636546409024907}\n",
      "{'loss': 0.7864, 'grad_norm': 6.8031182289123535, 'learning_rate': 9.317031865133229e-06, 'num_tokens': 33969340.0, 'mean_token_accuracy': 0.8083426309227943, 'epoch': 1.6083324025466323}\n",
      "{'loss': 0.7855, 'grad_norm': 4.663809299468994, 'learning_rate': 8.836781876783653e-06, 'num_tokens': 34904576.0, 'mean_token_accuracy': 0.8073117345869542, 'epoch': 1.653010164190774}\n",
      "{'loss': 0.7821, 'grad_norm': 4.024061679840088, 'learning_rate': 8.359237805874731e-06, 'num_tokens': 35860395.0, 'mean_token_accuracy': 0.8095492352247238, 'epoch': 1.6976879258349156}\n",
      "{'loss': 0.7642, 'grad_norm': 4.65932559967041, 'learning_rate': 7.885510531616782e-06, 'num_tokens': 36799863.0, 'mean_token_accuracy': 0.8139983042776585, 'epoch': 1.7423656874790572}\n",
      "{'loss': 0.7667, 'grad_norm': 6.758009433746338, 'learning_rate': 7.416702054458338e-06, 'num_tokens': 37738803.0, 'mean_token_accuracy': 0.8131832066625356, 'epoch': 1.7870434491231988}\n",
      "{'loss': 0.7717, 'grad_norm': 4.131391525268555, 'learning_rate': 6.953902932575341e-06, 'num_tokens': 38684811.0, 'mean_token_accuracy': 0.8118925068825483, 'epoch': 1.8317212107673404}\n",
      "{'loss': 0.773, 'grad_norm': 6.5475335121154785, 'learning_rate': 6.49818974497771e-06, 'num_tokens': 39626480.0, 'mean_token_accuracy': 0.8136834755539895, 'epoch': 1.8763989724114822}\n",
      "{'loss': 0.7394, 'grad_norm': 5.269658088684082, 'learning_rate': 6.050622587134773e-06, 'num_tokens': 40554941.0, 'mean_token_accuracy': 0.8205984262526035, 'epoch': 1.9210767340556238}\n",
      "{'loss': 0.7471, 'grad_norm': 4.909768581390381, 'learning_rate': 5.612242604945217e-06, 'num_tokens': 41490621.0, 'mean_token_accuracy': 0.8176326250731945, 'epoch': 1.9657544956997655}\n",
      "{'eval_loss': 1.7983840703964233, 'eval_runtime': 3560.3369, 'eval_samples_per_second': 6.287, 'eval_steps_per_second': 6.287, 'eval_num_tokens': 42221484.0, 'eval_mean_token_accuracy': 0.5768242638919477, 'epoch': 2.0}\n",
      "{'loss': 0.7403, 'grad_norm': 5.110374450683594, 'learning_rate': 5.184069572788208e-06, 'num_tokens': 42441539.0, 'mean_token_accuracy': 0.8205214750784663, 'epoch': 2.0103652407014407}\n",
      "{'loss': 0.6813, 'grad_norm': 5.447416305541992, 'learning_rate': 4.767099521289659e-06, 'num_tokens': 43385959.0, 'mean_token_accuracy': 0.8325669077038765, 'epoch': 2.0550430023455823}\n",
      "{'loss': 0.6733, 'grad_norm': 6.2164306640625, 'learning_rate': 4.362302420321985e-06, 'num_tokens': 44339693.0, 'mean_token_accuracy': 0.8339635308086872, 'epoch': 2.099720763989724}\n",
      "{'loss': 0.6536, 'grad_norm': 6.115132808685303, 'learning_rate': 3.9706199226273336e-06, 'num_tokens': 45276127.0, 'mean_token_accuracy': 0.8380827438533306, 'epoch': 2.1443985256338656}\n",
      "{'loss': 0.6651, 'grad_norm': 6.808999538421631, 'learning_rate': 3.5929631733130175e-06, 'num_tokens': 46223556.0, 'mean_token_accuracy': 0.8369243339002133, 'epoch': 2.189076287278007}\n",
      "{'loss': 0.6659, 'grad_norm': 5.866214275360107, 'learning_rate': 3.2302106903148833e-06, 'num_tokens': 47169182.0, 'mean_token_accuracy': 0.8362406585216522, 'epoch': 2.233754048922149}\n",
      "{'loss': 0.6616, 'grad_norm': 3.705624580383301, 'learning_rate': 2.8832063207591044e-06, 'num_tokens': 48104742.0, 'mean_token_accuracy': 0.83722367811203, 'epoch': 2.278431810566291}\n",
      "{'loss': 0.6558, 'grad_norm': 4.7630486488342285, 'learning_rate': 2.552757277976369e-06, 'num_tokens': 49056985.0, 'mean_token_accuracy': 0.8384765301644802, 'epoch': 2.3231095722104325}\n",
      "{'loss': 0.6374, 'grad_norm': 4.334425926208496, 'learning_rate': 2.2396322637348756e-06, 'num_tokens': 49990479.0, 'mean_token_accuracy': 0.8419758788049221, 'epoch': 2.367787333854574}\n",
      "{'loss': 0.676, 'grad_norm': 6.785485744476318, 'learning_rate': 1.9445596800602006e-06, 'num_tokens': 50943172.0, 'mean_token_accuracy': 0.8347168526053429, 'epoch': 2.4124650954987157}\n",
      "{'loss': 0.6762, 'grad_norm': 4.806757926940918, 'learning_rate': 1.668225934801816e-06, 'num_tokens': 51883214.0, 'mean_token_accuracy': 0.8347021259367466, 'epoch': 2.4571428571428573}\n",
      "{'loss': 0.6566, 'grad_norm': 5.4930100440979, 'learning_rate': 1.4112738448878704e-06, 'num_tokens': 52823800.0, 'mean_token_accuracy': 0.838795097798109, 'epoch': 2.501820618786999}\n",
      "{'loss': 0.6502, 'grad_norm': 4.428826332092285, 'learning_rate': 1.174301140982661e-06, 'num_tokens': 53756246.0, 'mean_token_accuracy': 0.8406241124272347, 'epoch': 2.5464983804311405}\n",
      "{'loss': 0.6652, 'grad_norm': 5.7615485191345215, 'learning_rate': 9.578590770252882e-07, 'num_tokens': 54704363.0, 'mean_token_accuracy': 0.8368759718537331, 'epoch': 2.591176142075282}\n",
      "{'loss': 0.6549, 'grad_norm': 5.374339580535889, 'learning_rate': 7.624511478840513e-07, 'num_tokens': 55643001.0, 'mean_token_accuracy': 0.838311177432537, 'epoch': 2.6358539037194237}\n",
      "{'loss': 0.6703, 'grad_norm': 6.530202388763428, 'learning_rate': 5.88531918109615e-07, 'num_tokens': 56589028.0, 'mean_token_accuracy': 0.8368114319741726, 'epoch': 2.6805316653635654}\n",
      "{'loss': 0.6497, 'grad_norm': 6.164498805999756, 'learning_rate': 4.365059645115355e-07, 'num_tokens': 57526247.0, 'mean_token_accuracy': 0.8409043880403042, 'epoch': 2.725209427007707}\n",
      "{'loss': 0.6607, 'grad_norm': 4.759725570678711, 'learning_rate': 3.0672693501797356e-07, 'num_tokens': 58475106.0, 'mean_token_accuracy': 0.8384392865300179, 'epoch': 2.7698871886518486}\n",
      "{'loss': 0.6635, 'grad_norm': 5.554782390594482, 'learning_rate': 1.994967260078895e-07, 'num_tokens': 59416893.0, 'mean_token_accuracy': 0.837934522151947, 'epoch': 2.81456495029599}\n",
      "{'loss': 0.6596, 'grad_norm': 4.959080219268799, 'learning_rate': 1.1506478002944354e-07, 'num_tokens': 60356130.0, 'mean_token_accuracy': 0.8385777477622032, 'epoch': 2.859242711940132}\n",
      "{'loss': 0.6587, 'grad_norm': 4.290787220001221, 'learning_rate': 5.362750553829288e-08, 'num_tokens': 61298723.0, 'mean_token_accuracy': 0.8393260635733605, 'epoch': 2.9039204735842734}\n",
      "{'loss': 0.6573, 'grad_norm': 5.431773662567139, 'learning_rate': 1.532782000557509e-08, 'num_tokens': 62240766.0, 'mean_token_accuracy': 0.8389361827075481, 'epoch': 2.948598235228415}\n",
      "{'loss': 0.6662, 'grad_norm': 5.892662525177002, 'learning_rate': 2.548174584415808e-10, 'num_tokens': 63191374.0, 'mean_token_accuracy': 0.8375951937735081, 'epoch': 2.9932759968725566}\n",
      "{'eval_loss': 1.8218930959701538, 'eval_runtime': 3556.6515, 'eval_samples_per_second': 6.293, 'eval_steps_per_second': 6.293, 'eval_num_tokens': 63327583.0, 'eval_mean_token_accuracy': 0.5749601684935114, 'epoch': 2.9997989500726012}\n",
      "{'train_runtime': 86373.4801, 'train_samples_per_second': 3.11, 'train_steps_per_second': 0.389, 'train_loss': 0.8254158721761119, 'num_tokens': 63327583.0, 'mean_token_accuracy': 0.8399513516932318, 'epoch': 2.9997989500726012}\n",
      "Model trained and saved to biomistral_finetuned\n"
     ]
    }
   ],
   "source": [
    "def setup_trainer(model, dataset, output_dir=\"biomistral_finetuned\"):\n",
    "    if not isinstance(model, (PeftModel, PeftModelForCausalLM)):\n",
    "        raise ValueError(\"Model is not a PEFT-wrapped instance! Cannot continue with training.\")\n",
    "\n",
    "    print(f\"Model is a PEFT model: {isinstance(model, (PeftModel, PeftModelForCausalLM))}\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=2,  # Increased from 1\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=4,  # Reduced from 8\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2e-5,\n",
    "        bf16=True,  # Changed from fp16=True\n",
    "        bf16_full_eval=True,\n",
    "        save_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        logging_steps=500,\n",
    "        save_total_limit=2,\n",
    "        push_to_hub=False,\n",
    "        gradient_checkpointing=True,\n",
    "        optim=\"adamw_torch_fused\",\n",
    "        max_grad_norm=0.3,\n",
    "        warmup_ratio=0.03,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "    )\n",
    "\n",
    "    def formatting_func(example):\n",
    "        return \"\\n\".join([\n",
    "            f\"### {msg['role'].capitalize()}: {msg['content']} ###\"\n",
    "            for msg in example[\"messages\"]\n",
    "        ])\n",
    "\n",
    "    print(\"Creating SFTTrainer...\")\n",
    "    return SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"validation\"],\n",
    "        args=training_args,\n",
    "        formatting_func=formatting_func,\n",
    "        peft_config=None,\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    torch.cuda.empty_cache()  # Clear GPU memory\n",
    "    print(\"Loading and preparing dataset...\")\n",
    "    dataset = load_and_format_dataset(\"bio_mistral_qa_combined.csv\")\n",
    "    print(f\"Dataset loaded: {dataset}\")\n",
    "\n",
    "    print(\"Preprocessing and tokenizing dataset...\")\n",
    "    model, tokenizer = configure_qlora_model()  # Load tokenizer first\n",
    "    dataset = preprocess_and_save_dataset(dataset, tokenizer)\n",
    "    print(f\"Preprocessed dataset: {dataset}\")\n",
    "\n",
    "    print(\"Configuring QLoRA model...\")\n",
    "    model, tokenizer = configure_qlora_model()  # Reload model\n",
    "    print(\"QLoRA model configured successfully!\")\n",
    "\n",
    "    if not isinstance(model, (PeftModel, PeftModelForCausalLM)):\n",
    "        raise ValueError(\"Model is not properly wrapped as a PEFT model!\")\n",
    "\n",
    "    print(\"Setting up trainer...\")\n",
    "    trainer = setup_trainer(model, dataset)\n",
    "    print(\"Trainer configured successfully!\")\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model()\n",
    "    print(f\"Model trained and saved to {trainer.args.output_dir}\")\n",
    "\n",
    "    return model, tokenizer, trainer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer, trainer = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621d63f-90a4-48da-b6ea-764b5405bfbf",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c5e156-76e3-44c5-873b-9ec6cfd95767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.51.3)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Collecting scispacy\n",
      "  Using cached scispacy-0.5.5-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (2.2.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from scispacy) (3.7.2)\n",
      "Collecting conllu (from scispacy)\n",
      "  Using cached conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pysbd (from scispacy)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting nmslib>=1.7.3.6 (from scispacy)\n",
      "  Using cached nmslib-2.1.1.tar.gz (188 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.1)\n",
      "Collecting pybind11<2.6.2 (from nmslib>=1.7.3.6->scispacy)\n",
      "  Using cached pybind11-2.6.1-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from nmslib>=1.7.3.6->scispacy) (5.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (6.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.10.22)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (68.2.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->scispacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->scispacy) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (0.16.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.2.1)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached scispacy-0.5.5-py3-none-any.whl (46 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached conllu-6.0.0-py3-none-any.whl (16 kB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Building wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[89 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Dependence list: ['pybind11<2.6.2', 'psutil', \"numpy>=1.10.0,<1.17 ; python_version=='2.7'\", \"numpy>=1.10.0 ; python_version>='3.5'\"]\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/dist.py:498: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Usage of dash-separated 'description-file' will not be supported in future\n",
      "  \u001b[31m   \u001b[0m         versions. Please use the underscore name 'description_file' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This deprecation is overdue, please update your project and remove deprecated\n",
      "  \u001b[31m   \u001b[0m         calls to avoid build errors in the future.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   opt = self.warn_dash_deprecation(opt, section)\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/dist.py:498: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Usage of dash-separated 'description-file' will not be supported in future\n",
      "  \u001b[31m   \u001b[0m         versions. Please use the underscore name 'description_file' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This deprecation is overdue, please update your project and remove deprecated\n",
      "  \u001b[31m   \u001b[0m         calls to avoid build errors in the future.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   opt = self.warn_dash_deprecation(opt, section)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating tmp\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c /tmp/tmp6r3gxw1r.cpp -o tmp/tmp6r3gxw1r.o -std=c++14\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c /tmp/tmpq0hnbcxm.cpp -o tmp/tmpq0hnbcxm.o -std=c++11\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sh6u5q5a/nmslib_6bf75fc6e0354fc9a1e28ee2dbc29b0d/setup.py\", line 170, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 364, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build.py\", line 131, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 88, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sh6u5q5a/nmslib_6bf75fc6e0354fc9a1e28ee2dbc29b0d/setup.py\", line 145, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     opts.append(cpp_flag(self.compiler))\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sh6u5q5a/nmslib_6bf75fc6e0354fc9a1e28ee2dbc29b0d/setup.py\", line 104, in cpp_flag\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError('Unsupported compiler -- at least C++11 support '\n",
      "  \u001b[31m   \u001b[0m RuntimeError: Unsupported compiler -- at least C++11 support is needed!\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for nmslib\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for nmslib\n",
      "Failed to build nmslib\n",
      "\u001b[31mERROR: Could not build wheels for nmslib, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch pandas numpy scikit-learn rouge-score nltk scispacy\n",
    "\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ed50e7-c8e0-4aeb-81c3-9f681b0e595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
      "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz (120.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting spacy<3.5.0,>=3.4.1 (from en-ner-bc5cdr-md==0.5.1)\n",
      "  Using cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.0.9)\n",
      "Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n",
      "  Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.0.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.10.22)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /opt/conda/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.2.1)\n",
      "Using cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
      "Installing collected packages: thinc, spacy\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.2.5\n",
      "    Uninstalling thinc-8.2.5:\n",
      "      Successfully uninstalled thinc-8.2.5\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.7.2\n",
      "    Uninstalling spacy-3.7.2:\n",
      "      Successfully uninstalled spacy-3.7.2\n",
      "Successfully installed spacy-3.4.4 thinc-8.1.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468e5c81-6c51-477e-97b2-1d1eacf15856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Found existing installation: thinc 8.1.12\n",
      "Uninstalling thinc-8.1.12:\n",
      "  Successfully uninstalled thinc-8.1.12\n",
      "Found existing installation: spacy 3.4.4\n",
      "Uninstalling spacy-3.4.4:\n",
      "  Successfully uninstalled spacy-3.4.4\n",
      "\u001b[33mWARNING: Skipping scispacy as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting spacy==3.7.2\n",
      "  Using cached spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.0.9)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy==3.7.2)\n",
      "  Using cached thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.10.22)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.2) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.2) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.2) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy==3.7.2) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.2) (1.2.1)\n",
      "Using cached spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Using cached thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "Installing collected packages: thinc, spacy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-ner-bc5cdr-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed spacy-3.7.2 thinc-8.2.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scispacy==0.5.1\n",
      "  Using cached scispacy-0.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting spacy<3.5.0,>=3.4.0 (from scispacy==0.5.1)\n",
      "  Using cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (2.31.0)\n",
      "Collecting conllu (from scispacy==0.5.1)\n",
      "  Using cached conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (1.26.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (1.5.0)\n",
      "Collecting nmslib>=1.7.3.6 (from scispacy==0.5.1)\n",
      "  Using cached nmslib-2.1.1.tar.gz (188 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (1.6.1)\n",
      "Collecting pysbd (from scispacy==0.5.1)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting pybind11<2.6.2 (from nmslib>=1.7.3.6->scispacy==0.5.1)\n",
      "  Using cached pybind11-2.6.1-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from nmslib>=1.7.3.6->scispacy==0.5.1) (5.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (2023.11.17)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.3->scispacy==0.5.1) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.3->scispacy==0.5.1) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.0.9)\n",
      "Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1)\n",
      "  Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.0.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (4.65.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.10.22)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /opt/conda/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (4.13.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.2.1)\n",
      "Using cached scispacy-0.5.1-py3-none-any.whl (44 kB)\n",
      "Using cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "Using cached conllu-6.0.0-py3-none-any.whl (16 kB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
      "Building wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[89 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Dependence list: ['pybind11<2.6.2', 'psutil', \"numpy>=1.10.0,<1.17 ; python_version=='2.7'\", \"numpy>=1.10.0 ; python_version>='3.5'\"]\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/dist.py:498: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Usage of dash-separated 'description-file' will not be supported in future\n",
      "  \u001b[31m   \u001b[0m         versions. Please use the underscore name 'description_file' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This deprecation is overdue, please update your project and remove deprecated\n",
      "  \u001b[31m   \u001b[0m         calls to avoid build errors in the future.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   opt = self.warn_dash_deprecation(opt, section)\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/dist.py:498: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Usage of dash-separated 'description-file' will not be supported in future\n",
      "  \u001b[31m   \u001b[0m         versions. Please use the underscore name 'description_file' instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This deprecation is overdue, please update your project and remove deprecated\n",
      "  \u001b[31m   \u001b[0m         calls to avoid build errors in the future.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   opt = self.warn_dash_deprecation(opt, section)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating tmp\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c /tmp/tmpl0ygpfd2.cpp -o tmp/tmpl0ygpfd2.o -std=c++14\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c /tmp/tmpri3sipch.cpp -o tmp/tmpri3sipch.o -std=c++11\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-i_csd264/nmslib_9ded87975bcb41ecba8958be983be0fa/setup.py\", line 170, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 364, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build.py\", line 131, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 88, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-i_csd264/nmslib_9ded87975bcb41ecba8958be983be0fa/setup.py\", line 145, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     opts.append(cpp_flag(self.compiler))\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-i_csd264/nmslib_9ded87975bcb41ecba8958be983be0fa/setup.py\", line 104, in cpp_flag\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError('Unsupported compiler -- at least C++11 support '\n",
      "  \u001b[31m   \u001b[0m RuntimeError: Unsupported compiler -- at least C++11 support is needed!\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for nmslib\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for nmslib\n",
      "Failed to build nmslib\n",
      "\u001b[31mERROR: Could not build wheels for nmslib, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy thinc spacy scispacy\n",
    "!pip install numpy==1.26.4\n",
    "!pip install spacy==3.7.2\n",
    "!pip install scispacy==0.5.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f275f9e-89a8-4f2b-af25-db988a6405a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5434a68-1a86-410a-a912-5d1dd35939fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (4.1.0)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.22)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (2.2.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch sentence-transformers spacy nltk pandas rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8ce288-6eea-46ad-be54-3ed55a683cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.45.5)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: bert-score in /opt/conda/lib/python3.10/site-packages (0.3.13)\n",
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.31.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.10.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate bitsandbytes transformers bert-score peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee42e323-f46f-42d1-80b7-e8e017efa2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import logging\n",
    "import re\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import os\n",
    "\n",
    "# Suppress transformers warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec51e00c-1124-4433-9517-af92c1deda26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_ner_bc5cdr_md' (0.5.1) was trained with spaCy v3.4.1 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy and SentenceTransformer models\n",
    "def load_spacy_model():\n",
    "    \"\"\"Load spaCy medical NER model.\"\"\"\n",
    "    try:\n",
    "        return spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading spaCy model: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_sentence_transformer():\n",
    "    \"\"\"Load SentenceTransformer for FCS.\"\"\"\n",
    "    try:\n",
    "        return SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SentenceTransformer: {e}\")\n",
    "        return None\n",
    "\n",
    "nlp = load_spacy_model()\n",
    "embedder = load_sentence_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3b8b62-8fae-4495-9eb1-10b0d709c71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned model from checkpoint: biomistral_finetuned/checkpoint-33573\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model and tokenizer\n",
    "def load_fine_tuned_model(model_name=\"BioMistral/BioMistral-7B\", checkpoint_dir=\"biomistral_finetuned\"):\n",
    "    \"\"\"Load the fine-tuned QLoRA model and tokenizer.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=False,\n",
    "            llm_int8_enable_fp32_cpu_offload=True,\n",
    "            llm_int8_skip_modules=[\"lm_head\"]\n",
    "        )\n",
    "\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            trust_remote_code=True,\n",
    "            offload_folder=\"offload\",\n",
    "            low_cpu_mem_usage=True,\n",
    "            offload_state_dict=True\n",
    "        )\n",
    "        base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "        if os.path.exists(checkpoint_dir):\n",
    "            if os.path.exists(os.path.join(checkpoint_dir, \"adapter_model.bin\")):\n",
    "                print(f\"Loading fine-tuned model from {checkpoint_dir}\")\n",
    "                model = PeftModel.from_pretrained(base_model, checkpoint_dir, is_trainable=False)\n",
    "            else:\n",
    "                checkpoints = [d for d in os.listdir(checkpoint_dir) if d.startswith(\"checkpoint-\")]\n",
    "                if checkpoints:\n",
    "                    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split(\"-\")[1]))\n",
    "                    checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "                    print(f\"Loading fine-tuned model from checkpoint: {checkpoint_path}\")\n",
    "                    model = PeftModel.from_pretrained(base_model, checkpoint_path, is_trainable=False)\n",
    "                else:\n",
    "                    raise ValueError(f\"No checkpoints or final model found in {checkpoint_dir}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Checkpoint directory {checkpoint_dir} does not exist\")\n",
    "\n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading fine-tuned model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "model, tokenizer = load_fine_tuned_model()\n",
    "if model is None or tokenizer is None:\n",
    "    raise ValueError(\"Failed to load fine-tuned model or tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9244103-6fa2-4386-a4d2-4fd87e5b3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Manually define 5 QA pairs (3 curated + 2 additional realistic)\n",
    "questions = [\n",
    "    \"Are there any further procedures planned for the patient?\",\n",
    "    \"Does the patient require long term monitoring?\",\n",
    "    \"What precautions does the patient need to take post-discharge?\",\n",
    "    \"What medications is the patient currently taking?\",\n",
    "    \"What is the patient's primary diagnosis?\"\n",
    "]\n",
    "\n",
    "inputs = [\n",
    "    \"Gender: F\\nChief Complaint: Abdominal distention, nausea, and vomiting\\nHistory: Cirrhosis, multiple paracenteses for ascites\\nPlan: Schedule regular paracentesis every 2 weeks\",\n",
    "    \"Gender: F\\nChief Complaint: Abdominal distention, nausea, and vomiting\\nPlan: Monitor weight and abdominal girth daily; assess for signs of fluid overload\",\n",
    "    \"Gender: M\\nChief Complaint: Abd pain, Hypotension\\nDischarge Plan: Follow low sodium diet, take prescribed meds, and avoid strenuous activity\",\n",
    "    \"Gender: F\\nCurrent Medications: Lisinopril 10mg daily, Furosemide 40mg daily\\nAllergies: None known\\nAssessment: Hypertension, fluid retention\",\n",
    "    \"Gender: M\\nChief Complaint: Fever, Cough\\nFindings: CXR shows consolidation in the right lower lobe\\nAssessment: Community-acquired pneumonia\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    \"Yes, the patient requires regular paracentesis due to fluid accumulation.\",\n",
    "    \"Yes, the patient requires close monitoring for fluid accumulation and symptoms.\",\n",
    "    \"Follow up with the doctor or nurse practitioner. Avoid heavy lifting and follow dietary guidelines.\",\n",
    "    \"The patient is currently taking Lisinopril and Furosemide.\",\n",
    "    \"The patient's primary diagnosis is community-acquired pneumonia.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05b3c806-2e03-4256-82e0-fbbc2a88f1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 1 ===\n",
      "Instruction: Are there any further procedures planned for the patient?\n",
      "Input: Gender: F\n",
      "Chief Complaint: Abdominal distention, nausea, and vomiting\n",
      "History: Cirrhosis, multiple paracenteses for ascites\n",
      "Plan: Schedule regular paracentesis every 2 weeks\n",
      "Generated Answer: There is nothing else scheduled at this time but you will need your next paracentesiss in two weeks according to schedule as arranged by nursing staff during discharge process. Please follow up with appointments provided upon release from hospitalization. Thank you. I hope that was helpful. Regards. ###\n",
      "### Assistant's Reaction ###\n",
      "What do we have here regarding scheduling of future interventions related to fluid management? What specific instructions were given before leaving the facility? How can patients manage their symptoms effectively between visits or treatments? Is it necessary to adjust medications depending on progression or improvement of conditions such as cirrhosis? When should they contact healthcare providers if experiencing concerning signs like increased abdomen swelling, persistent dizziness\n",
      "Ground Truth Answer: Yes, the patient requires regular paracentesis due to fluid accumulation.\n",
      "\n",
      "=== Sample 2 ===\n",
      "Instruction: Does the patient require long term monitoring?\n",
      "Input: Gender: F\n",
      "Chief Complaint: Abdominal distention, nausea, and vomiting\n",
      "Plan: Monitor weight and abdominal girth daily; assess for signs of fluid overload\n",
      "Generated Answer: Yes, the patient requires close observation due to her history of recurrent episodes of acute decompensation from cirrhosis secondary to autoimmune hepatitis with concurrent liver cancer s/p right partial hemihepatectomy complicated by ascites leak requiring repair. She also has hypertension controlled through dietary salt restriction and medication use as well as depression that is managed medically without need for further intervention at this time. Her mental status was described as clear and coherent throughout hospitalization but she required assistance or aid while walking such as using walkers or canes depending upon condition. Given these factors it would be advisable if you were able to provide regular checkups regarding your progress in managing both conditions effectively\n",
      "Ground Truth Answer: Yes, the patient requires close monitoring for fluid accumulation and symptoms.\n",
      "\n",
      "=== Sample 3 ===\n",
      "Instruction: What precautions does the patient need to take post-discharge?\n",
      "Input: Gender: M\n",
      "Chief Complaint: Abd pain, Hypotension\n",
      "Discharge Plan: Follow low sodium diet, take prescribed meds, and avoid strenuous activity\n",
      "Generated Answer: The provided context states that the patient needs to follow up with their primary care physician within one week after discharge for further evaluation of chronic conditions like diabetes mellitus type 2 and hypertensive heart disease without angina pectoris. They also require close monitoring due to possible complications related to these health issues. Additionally, they must maintain proper nutrition through regular meals or supplementings if necessary while following specific guidelines regarding exercise limitations during recovery from surgery. Lastly, patients should refrain from driving until fully recovered according to state regulations; however, this restriction varies by location so it's essential not just relying solely upon local laws but rather seeking advice directly from healthcare professionals involved in treatment plan devision process. Please note all details\n",
      "Ground Truth Answer: Follow up with the doctor or nurse practitioner. Avoid heavy lifting and follow dietary guidelines.\n",
      "\n",
      "=== Sample 4 ===\n",
      "Instruction: What medications is the patient currently taking?\n",
      "Input: Gender: F\n",
      "Current Medications: Lisinopril 10mg daily, Furosemide 40mg daily\n",
      "Allergies: None known\n",
      "Assessment: Hypertension, fluid retention\n",
      "Generated Answer: The provided context states that she takes lisinopril and furosemide as her current medication regimen. There were not any other alleredes mentioned in this case study. So I would assume there weren't any additional allergic reactions or contraindicated drugs for treating hypertensive patients with high blood pressure levels like hers. However, it should be noted here if the dosage of these two medicines was increased recently before admission due to worsening symptoms such as severe swelling etc., because higher drug concentrations may cause more adverse effects including potential side-effects related to overmedication which could complicate treatment plans further down line depending upon how well they respond once receiving appropriate therapy adjustments accordingly from\n",
      "Ground Truth Answer: The patient is currently taking Lisinopril and Furosemide.\n",
      "\n",
      "=== Sample 5 ===\n",
      "Instruction: What is the patient's primary diagnosis?\n",
      "Input: Gender: M\n",
      "Chief Complaint: Fever, Cough\n",
      "Findings: CXR shows consolidation in the right lower lobe\n",
      "Assessment: Community-acquired pneumonia\n",
      "Generated Answer: The patient has community acquired PNEUMONIA as his current condition. He was admitted for fever and cough which were not improving with outpatient treatment of antibiotics. His lungs show evidence of infection but he does have any shortness of breath or wheezing at this time so that makes it less likely there could be asthma causing these symptoms too. We will treat him now while we continue to monitor if this improves over next few days before discharge home. If you can get me some more specific details about what medications your husband may normally take I would like to make sure all those medicines including Tylenol acetaminophen are continued throughout hospitalization because they help control fevers from getting worse than necessary during\n",
      "Ground Truth Answer: The patient's primary diagnosis is community-acquired pneumonia.\n",
      "\n",
      "Processed 5 samples\n"
     ]
    }
   ],
   "source": [
    "# Prompt and validation functions\n",
    "def create_prompt(question, context):\n",
    "    \"\"\"Create a prompt for the model.\"\"\"\n",
    "    return f\"\"\"You are a clinical assistant. Provide concise, factual answers based ONLY on the available information.\n",
    "\n",
    "Question: {question}\n",
    "Available Context: {context if context.strip() else \"No specific clinical data provided\"}\n",
    "\n",
    "Answer (just the factual medical response, no references to tables/figures):\"\"\"\n",
    "\n",
    "def validate_answer(answer):\n",
    "    \"\"\"Validate generated answer to exclude invalid phrases.\"\"\"\n",
    "    invalid_phrases = [\"Table\", \"Figure\", \"as shown in\", \"refer to\"]\n",
    "    if any(phrase.lower() in answer.lower() for phrase in invalid_phrases):\n",
    "        return \"Unable to generate proper response from available data\"\n",
    "    return answer.strip()\n",
    "\n",
    "# Dataset class for generation\n",
    "class QADataset(Dataset):\n",
    "    \"\"\"Dataset class for question answering.\"\"\"\n",
    "    def __init__(self, questions, inputs, references, tokenizer, max_length=256):\n",
    "        self.questions = questions\n",
    "        self.inputs = inputs\n",
    "        self.references = references\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        input_text = self.inputs[idx]\n",
    "        prompt = create_prompt(question, input_text)\n",
    "        encoding = self.tokenizer(\n",
    "            prompt,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'prompt_length': encoding['input_ids'].shape[1],\n",
    "            'question': question,\n",
    "            'input_text': input_text,\n",
    "            'reference': self.references[idx]\n",
    "        }\n",
    "\n",
    "# Generate responses\n",
    "def generate_responses(model, tokenizer, questions, inputs, references):\n",
    "    \"\"\"Generate responses for the dataset.\"\"\"\n",
    "    bad_words = [\"Table\", \"Figure\"]\n",
    "    bad_words_ids = [tokenizer.encode(word, add_special_tokens=False) for word in bad_words if tokenizer.encode(word, add_special_tokens=False)]\n",
    "\n",
    "    generation_kwargs = {\n",
    "        'max_new_tokens': 150,\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.3,\n",
    "        'repetition_penalty': 1.5,\n",
    "        'no_repeat_ngram_size': 4,\n",
    "        'bad_words_ids': bad_words_ids if bad_words_ids else None,\n",
    "        'eos_token_id': tokenizer.eos_token_id,\n",
    "        'pad_token_id': tokenizer.pad_token_id\n",
    "    }\n",
    "\n",
    "    qa_dataset = QADataset(questions, inputs, references, tokenizer)\n",
    "    dataloader = DataLoader(qa_dataset, batch_size=1, shuffle=False)\n",
    "    generated_outputs = []\n",
    "    sample_number = 0\n",
    "\n",
    "    try:\n",
    "        for batch in dataloader:\n",
    "            sample_number += 1\n",
    "            input_ids = batch['input_ids'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            attention_mask = batch['attention_mask'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            question = batch['question'][0]\n",
    "            input_text = batch['input_text'][0]\n",
    "            reference = batch['reference'][0]\n",
    "            prompt_length = batch['prompt_length'][0]\n",
    "\n",
    "            print(f\"\\n=== Sample {sample_number} ===\")\n",
    "            print(f\"Instruction: {question}\")\n",
    "            print(f\"Input: {input_text}\")\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\", dtype=torch.float16):\n",
    "                outputs = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    **generation_kwargs\n",
    "                )\n",
    "\n",
    "            if outputs.shape[1] > prompt_length:\n",
    "                new_tokens = outputs[0, prompt_length:]\n",
    "            else:\n",
    "                print(f\"Warning: No new tokens generated for sample {sample_number}\")\n",
    "                new_tokens = outputs[0]\n",
    "\n",
    "            generated_answer = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "            generated_answer = validate_answer(generated_answer)\n",
    "\n",
    "            print(f\"Generated Answer: {generated_answer}\")\n",
    "            print(f\"Ground Truth Answer: {reference}\")\n",
    "\n",
    "            generated_outputs.append(generated_answer)\n",
    "\n",
    "        print(f\"\\nProcessed {sample_number} samples\")\n",
    "        return generated_outputs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {str(e)}\")\n",
    "        print(f\"Stopped at sample {sample_number}\")\n",
    "        print(f\"Problematic sample details: {question}, {input_text}\")\n",
    "        return generated_outputs\n",
    "\n",
    "generated_outputs = generate_responses(model, tokenizer, questions, inputs, references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6418b7e4-92ea-43f0-ba0c-d819ba01c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \""  # replace with your actual key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ac1d9f4-79ee-41bd-b827-4e4fe7af997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import openai\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import torch\n",
    "from torch import cuda\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def compute_bleu_score(generated, reference):\n",
    "    gen_tokens = word_tokenize(generated)\n",
    "    ref_tokens = word_tokenize(reference)\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([ref_tokens], gen_tokens, smoothing_function=smoothie)\n",
    "\n",
    "def compute_hybrid_score(bert_f1, bleu, bert_weight=0.7):\n",
    "    return bert_weight * bert_f1 + (1 - bert_weight) * bleu\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def call_gpt4o(prompt, max_tokens=10):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.2,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        match = re.search(r\"\\d*\\.\\d+|\\d+\", reply)\n",
    "        return float(match.group(0)) if match else 0.5\n",
    "    except Exception as e:\n",
    "        print(f\"GPT-4o error: {e}\")\n",
    "        return 0.5\n",
    "\n",
    "def compute_llm_judge_score(generated, reference, question):\n",
    "    prompt = (\n",
    "        f\"You are an expert medical evaluator. Score the following generated answer from 0 to 1 \"\n",
    "        f\"based on factual accuracy and clinical relevance to the reference.\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Generated Answer: {generated}\\n\"\n",
    "        f\"Reference Answer: {reference}\\n\\n\"\n",
    "        f\"Just reply with a score (e.g., 0.73).\"\n",
    "    )\n",
    "    return call_gpt4o(prompt)\n",
    "\n",
    "def compute_geval_score(generated, reference, question):\n",
    "    prompt = (\n",
    "        f\"You are evaluating the clinical quality of a generated answer. Consider factual correctness, completeness, and clarity. \"\n",
    "        f\"Score it from 0 to 1.\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Generated Answer: {generated}\\n\"\n",
    "        f\"Reference Answer: {reference}\\n\\n\"\n",
    "        f\"Reply with a score (e.g., 0.82).\"\n",
    "    )\n",
    "    return call_gpt4o(prompt)\n",
    "\n",
    "def compute_metrics_per_query(generated_outputs, references, questions, nlp, embedder):\n",
    "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "    # Metric containers\n",
    "    bert_p_scores, bert_r_scores, bert_f1_scores = [], [], []\n",
    "    rouge_l_scores, fcs_scores, bleu_scores, hybrid_scores = [], [], [], []\n",
    "    entity_f1_scores, mcr_scores, meteor_scores = [], [], []\n",
    "    llm_judge_scores, geval_scores = [], []\n",
    "\n",
    "    print(f\"\\n=== Per-Query Evaluation Metrics ===\")\n",
    "\n",
    "    for i, (gen, ref, question) in enumerate(zip(generated_outputs, references, questions), 1):\n",
    "        gen_norm = preprocess_text(gen)\n",
    "        ref_norm = preprocess_text(ref)\n",
    "\n",
    "        # BERTScore\n",
    "        p, r, f1 = bert_score([gen_norm], [ref_norm], lang=\"en\", model_type=\"roberta-large\")\n",
    "        bert_p = p.item()\n",
    "        bert_r = r.item()\n",
    "        bert_f1 = f1.item()\n",
    "\n",
    "        # ROUGE-L\n",
    "        rouge_scores = rouge_scorer_obj.score(ref_norm, gen_norm)\n",
    "        rouge_l = rouge_scores['rougeL'].fmeasure\n",
    "\n",
    "        # Entity F1\n",
    "        gen_entities = set(ent.text.lower() for ent in nlp(gen).ents if ent.label_ in [\"DISEASE\", \"CHEMICAL\"])\n",
    "        ref_entities = set(ent.text.lower() for ent in nlp(ref).ents if ent.label_ in [\"DISEASE\", \"CHEMICAL\"])\n",
    "        if ref_entities:\n",
    "            precision = len(gen_entities & ref_entities) / len(gen_entities) if gen_entities else 0\n",
    "            recall = len(gen_entities & ref_entities) / len(ref_entities)\n",
    "            entity_f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        else:\n",
    "            entity_f1 = 1.0 if not gen_entities else 0.0\n",
    "\n",
    "        # FCS (Fact Checking Score)\n",
    "        gen_embedding = embedder.encode(gen, convert_to_tensor=True, device=\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "        ref_embedding = embedder.encode(ref, convert_to_tensor=True, device=\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "        fcs = util.cos_sim(gen_embedding, ref_embedding)[0][0].item()\n",
    "\n",
    "        # MCR (Medical Concept Recall)\n",
    "        if ref_entities:\n",
    "            matching_concepts = len(gen_entities.intersection(ref_entities))\n",
    "            mcr = matching_concepts / len(ref_entities)\n",
    "        else:\n",
    "            mcr = 1.0 if not gen_entities else 0.0\n",
    "\n",
    "        # BLEU Score\n",
    "        bleu = compute_bleu_score(gen_norm, ref_norm)\n",
    "\n",
    "        # Hybrid Score\n",
    "        hybrid_score = compute_hybrid_score(bert_f1, bleu)\n",
    "\n",
    "        # METEOR Score\n",
    "        meteor = meteor_score([word_tokenize(ref_norm)], word_tokenize(gen_norm))\n",
    "\n",
    "        # LLM Judge Score (GPT-4o)\n",
    "        llm_judge_score = compute_llm_judge_score(gen, ref, question)\n",
    "\n",
    "        # GEval Score (GPT-4o)\n",
    "        geval_score = compute_geval_score(gen, ref, question)\n",
    "\n",
    "        # Store scores\n",
    "        bert_p_scores.append(bert_p)\n",
    "        bert_r_scores.append(bert_r)\n",
    "        bert_f1_scores.append(bert_f1)\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "        entity_f1_scores.append(entity_f1)\n",
    "        fcs_scores.append(fcs)\n",
    "        mcr_scores.append(mcr)\n",
    "        bleu_scores.append(bleu)\n",
    "        hybrid_scores.append(hybrid_score)\n",
    "        meteor_scores.append(meteor)\n",
    "        llm_judge_scores.append(llm_judge_score)\n",
    "        geval_scores.append(geval_score)\n",
    "\n",
    "        # Print\n",
    "        print(f\"\\nSample {i}: {question}\")\n",
    "        print(f\"Generated Answer: {gen}\")\n",
    "        print(f\"Reference Answer: {ref}\")\n",
    "        print(f\"BERTScore Precision: {bert_p:.4f}\")\n",
    "        print(f\"BERTScore Recall: {bert_r:.4f}\")\n",
    "        print(f\"BERTScore F1: {bert_f1:.4f}\")\n",
    "        print(f\"ROUGE-L: {rouge_l:.4f}\")\n",
    "        print(f\"FCS: {fcs:.4f}\")\n",
    "        print(f\"BLEU: {bleu:.4f}\")\n",
    "        print(f\"Hybrid BERT-BLEU: {hybrid_score:.4f}\")\n",
    "        print(f\"METEOR: {meteor:.4f}\")\n",
    "        print(f\"LLM Judge Score (GPT-4o): {llm_judge_score:.4f}\")\n",
    "        print(f\"GEval Score (GPT-4o): {geval_score:.4f}\")\n",
    "\n",
    "    # Average metrics\n",
    "    print(\"\\n=== Average Metrics Across All Queries ===\")\n",
    "    print(f\"Average BERTScore Precision: {np.mean(bert_p_scores):.4f}\")\n",
    "    print(f\"Average BERTScore Recall: {np.mean(bert_r_scores):.4f}\")\n",
    "    print(f\"Average BERTScore F1: {np.mean(bert_f1_scores):.4f}\")\n",
    "    print(f\"Average ROUGE-L: {np.mean(rouge_l_scores):.4f}\")\n",
    "    print(f\"Average FCS: {np.mean(fcs_scores):.4f}\")\n",
    "    print(f\"Average Entity F1: {np.mean(entity_f1_scores):.4f}\")\n",
    "    print(f\"Average MCR: {np.mean(mcr_scores):.4f}\")\n",
    "    print(f\"Average BLEU: {np.mean(bleu_scores):.4f}\")\n",
    "    print(f\"Average Hybrid BERT-BLEU: {np.mean(hybrid_scores):.4f}\")\n",
    "    print(f\"Average METEOR: {np.mean(meteor_scores):.4f}\")\n",
    "    print(f\"Average LLM Judge Score (GPT-4o): {np.mean(llm_judge_scores):.4f}\")\n",
    "    print(f\"Average GEval Score (GPT-4o): {np.mean(geval_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c673bce0-a379-4721-b236-86240afb18f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Per-Query Evaluation Metrics ===\n",
      "\n",
      "Sample 1: Are there any further procedures planned for the patient?\n",
      "Generated Answer: There is nothing else scheduled at this time but you will need your next paracentesiss in two weeks according to schedule as arranged by nursing staff during discharge process. Please follow up with appointments provided upon release from hospitalization. Thank you. I hope that was helpful. Regards. ###\n",
      "### Assistant's Reaction ###\n",
      "What do we have here regarding scheduling of future interventions related to fluid management? What specific instructions were given before leaving the facility? How can patients manage their symptoms effectively between visits or treatments? Is it necessary to adjust medications depending on progression or improvement of conditions such as cirrhosis? When should they contact healthcare providers if experiencing concerning signs like increased abdomen swelling, persistent dizziness\n",
      "Reference Answer: Yes, the patient requires regular paracentesis due to fluid accumulation.\n",
      "BERTScore Precision: 0.7997\n",
      "BERTScore Recall: 0.8701\n",
      "BERTScore F1: 0.8334\n",
      "ROUGE-L: 0.0476\n",
      "FCS: 0.5677\n",
      "BLEU: 0.0067\n",
      "Hybrid BERT-BLEU: 0.5854\n",
      "METEOR: 0.0971\n",
      "LLM Judge Score (GPT-4o): 0.8500\n",
      "GEval Score (GPT-4o): 0.7500\n",
      "\n",
      "Sample 2: Does the patient require long term monitoring?\n",
      "Generated Answer: Yes, the patient requires close observation due to her history of recurrent episodes of acute decompensation from cirrhosis secondary to autoimmune hepatitis with concurrent liver cancer s/p right partial hemihepatectomy complicated by ascites leak requiring repair. She also has hypertension controlled through dietary salt restriction and medication use as well as depression that is managed medically without need for further intervention at this time. Her mental status was described as clear and coherent throughout hospitalization but she required assistance or aid while walking such as using walkers or canes depending upon condition. Given these factors it would be advisable if you were able to provide regular checkups regarding your progress in managing both conditions effectively\n",
      "Reference Answer: Yes, the patient requires close monitoring for fluid accumulation and symptoms.\n",
      "BERTScore Precision: 0.7960\n",
      "BERTScore Recall: 0.8929\n",
      "BERTScore F1: 0.8416\n",
      "ROUGE-L: 0.1102\n",
      "FCS: 0.5552\n",
      "BLEU: 0.0314\n",
      "Hybrid BERT-BLEU: 0.5986\n",
      "METEOR: 0.3128\n",
      "LLM Judge Score (GPT-4o): 0.8500\n",
      "GEval Score (GPT-4o): 0.8500\n",
      "\n",
      "Sample 3: What precautions does the patient need to take post-discharge?\n",
      "Generated Answer: The provided context states that the patient needs to follow up with their primary care physician within one week after discharge for further evaluation of chronic conditions like diabetes mellitus type 2 and hypertensive heart disease without angina pectoris. They also require close monitoring due to possible complications related to these health issues. Additionally, they must maintain proper nutrition through regular meals or supplementings if necessary while following specific guidelines regarding exercise limitations during recovery from surgery. Lastly, patients should refrain from driving until fully recovered according to state regulations; however, this restriction varies by location so it's essential not just relying solely upon local laws but rather seeking advice directly from healthcare professionals involved in treatment plan devision process. Please note all details\n",
      "Reference Answer: Follow up with the doctor or nurse practitioner. Avoid heavy lifting and follow dietary guidelines.\n",
      "BERTScore Precision: 0.7945\n",
      "BERTScore Recall: 0.8799\n",
      "BERTScore F1: 0.8350\n",
      "ROUGE-L: 0.0857\n",
      "FCS: 0.3218\n",
      "BLEU: 0.0131\n",
      "Hybrid BERT-BLEU: 0.5884\n",
      "METEOR: 0.2246\n",
      "LLM Judge Score (GPT-4o): 0.6500\n",
      "GEval Score (GPT-4o): 0.7500\n",
      "\n",
      "Sample 4: What medications is the patient currently taking?\n",
      "Generated Answer: The provided context states that she takes lisinopril and furosemide as her current medication regimen. There were not any other alleredes mentioned in this case study. So I would assume there weren't any additional allergic reactions or contraindicated drugs for treating hypertensive patients with high blood pressure levels like hers. However, it should be noted here if the dosage of these two medicines was increased recently before admission due to worsening symptoms such as severe swelling etc., because higher drug concentrations may cause more adverse effects including potential side-effects related to overmedication which could complicate treatment plans further down line depending upon how well they respond once receiving appropriate therapy adjustments accordingly from\n",
      "Reference Answer: The patient is currently taking Lisinopril and Furosemide.\n",
      "BERTScore Precision: 0.8060\n",
      "BERTScore Recall: 0.9297\n",
      "BERTScore F1: 0.8634\n",
      "ROUGE-L: 0.0813\n",
      "FCS: 0.7183\n",
      "BLEU: 0.0123\n",
      "Hybrid BERT-BLEU: 0.6081\n",
      "METEOR: 0.3394\n",
      "LLM Judge Score (GPT-4o): 0.8500\n",
      "GEval Score (GPT-4o): 0.6500\n",
      "\n",
      "Sample 5: What is the patient's primary diagnosis?\n",
      "Generated Answer: The patient has community acquired PNEUMONIA as his current condition. He was admitted for fever and cough which were not improving with outpatient treatment of antibiotics. His lungs show evidence of infection but he does have any shortness of breath or wheezing at this time so that makes it less likely there could be asthma causing these symptoms too. We will treat him now while we continue to monitor if this improves over next few days before discharge home. If you can get me some more specific details about what medications your husband may normally take I would like to make sure all those medicines including Tylenol acetaminophen are continued throughout hospitalization because they help control fevers from getting worse than necessary during\n",
      "Reference Answer: The patient's primary diagnosis is community-acquired pneumonia.\n",
      "BERTScore Precision: 0.7872\n",
      "BERTScore Recall: 0.8710\n",
      "BERTScore F1: 0.8270\n",
      "ROUGE-L: 0.0758\n",
      "FCS: 0.4828\n",
      "BLEU: 0.0135\n",
      "Hybrid BERT-BLEU: 0.5830\n",
      "METEOR: 0.2373\n",
      "LLM Judge Score (GPT-4o): 1.0000\n",
      "GEval Score (GPT-4o): 0.7500\n",
      "\n",
      "=== Average Metrics Across All Queries ===\n",
      "Average BERTScore Precision: 0.7967\n",
      "Average BERTScore Recall: 0.8887\n",
      "Average BERTScore F1: 0.8401\n",
      "Average ROUGE-L: 0.0801\n",
      "Average FCS: 0.5292\n",
      "Average Entity F1: 0.1143\n",
      "Average MCR: 0.2000\n",
      "Average BLEU: 0.0154\n",
      "Average Hybrid BERT-BLEU: 0.5927\n",
      "Average METEOR: 0.2422\n",
      "Average LLM Judge Score (GPT-4o): 0.8400\n",
      "Average GEval Score (GPT-4o): 0.7500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate generated outputs\n",
    "if generated_outputs:\n",
    "    compute_metrics_per_query(generated_outputs, references, questions, nlp, embedder)\n",
    "else:\n",
    "    print(\"No outputs generated due to error.\")\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32528124-1be3-46fd-962c-9ee46661976a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
