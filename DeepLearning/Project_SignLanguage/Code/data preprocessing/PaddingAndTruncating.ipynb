{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e637162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8328d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 135 #135 for 95th percentile , or 90 for 90th percentile\n",
    "#pad sequences with length less than max_seq_length with value -1\n",
    "#truncate sequences with length more than max_seq_length to max_seq_length\n",
    "PAD_VALUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e90fbd-42f2-4c1d-86f6-b3366a52d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed837c-9309-4f16-8626-a2369ddf5bc9",
   "metadata": {},
   "source": [
    "## Truncation and padding on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7fdffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_methods = ['starting', 'ending', 'middle', 'random sampling', 'uniform sampling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec4a879-05b4-4c68-b5f5-7ad93fe1d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Padding ===\n",
    "def pad_tensor(tensor, max_length, pad_value):\n",
    "    current_len = tensor.shape[0]\n",
    "    if current_len >= max_length:\n",
    "        return tensor[:max_length]\n",
    "    else:\n",
    "        pad_size = max_length - current_len\n",
    "        padding = torch.full((pad_size, tensor.shape[1]), pad_value, device=tensor.device)\n",
    "        return torch.cat([tensor, padding], dim=0)\n",
    "\n",
    "\n",
    "# === Truncation + Padding ===\n",
    "def pad_or_truncate_tensor(tensor, max_length, pad_value, method=\"uniform sampling\"):\n",
    "    if tensor.shape[0] > max_length:\n",
    "        if method == \"starting\":\n",
    "            return tensor[:max_length]\n",
    "        elif method == \"ending\":\n",
    "            return tensor[-max_length:]\n",
    "        elif method == \"middle\":\n",
    "            mid = tensor.shape[0] // 2\n",
    "            start = mid - (max_length // 2)\n",
    "            return tensor[start:start + max_length]\n",
    "        elif method == \"random sampling\":\n",
    "            start = torch.randint(0, tensor.shape[0] - max_length + 1, (1,)).item()\n",
    "            return tensor[start:start + max_length]\n",
    "        elif method == \"uniform sampling\":\n",
    "            indices = torch.linspace(0, tensor.shape[0] - 1, steps=max_length).long()\n",
    "            return tensor[indices]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown truncation method: {method}\")\n",
    "    else:\n",
    "        return pad_tensor(tensor, max_length, pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad38b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Get all parquet file paths ===\n",
    "input_dir = 'train_landmark_files_normalized'\n",
    "output_dir = 'train_landmark_files_final_prepared'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf43123e-c447-48b3-96bc-0331fc9a2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6 = []\n",
    "for dirname, _, filenames in os.walk(input_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.parquet'):\n",
    "            dataset6.append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280f9cf",
   "metadata": {},
   "source": [
    "SAVE PADDED AND TRUNCATED DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5856393",
   "metadata": {},
   "source": [
    "This preprocessed data can be used for training all the three models: Transformer, LSTM, RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8182de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94477/94477 [3:22:44<00:00,  7.77it/s]  \n"
     ]
    }
   ],
   "source": [
    "# === Process each file ===\n",
    "chosen_method = \"uniform sampling\"  # Change this to use a different truncation method\n",
    "\n",
    "for directory in tqdm(dataset6):\n",
    "    # Parse path parts\n",
    "    path_parts = directory.split(\"/\")\n",
    "    frame_num = path_parts[-2]\n",
    "    file_name = path_parts[-1]\n",
    "    output_file_path = os.path.join(output_dir, frame_num, file_name)\n",
    "\n",
    "    # Read parquet file\n",
    "    df = pd.read_parquet(directory)\n",
    "    if df.empty:\n",
    "        continue  # Skip empty files to avoid errors\n",
    "\n",
    "    # Convert to tensor and move to GPU\n",
    "    data_tensor = torch.tensor(df.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Pad or truncate using GPU\n",
    "    processed_tensor = pad_or_truncate_tensor(data_tensor, MAX_SEQ_LEN, PAD_VALUE, method=chosen_method)\n",
    "\n",
    "    # Convert back to DataFrame on CPU\n",
    "    processed_df = pd.DataFrame(processed_tensor.cpu().numpy(), columns=df.columns)\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    processed_df.to_parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed045a-6011-4e90-8e67-70b108557db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl",
   "language": "python",
   "name": "asl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
