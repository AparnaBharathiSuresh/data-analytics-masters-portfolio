{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "120d7a0a-b5fa-4d83-957e-0609e0f82848",
      "metadata": {
        "id": "120d7a0a-b5fa-4d83-957e-0609e0f82848"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return (x + torch.abs(x)) / 2\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).float()\n",
        "\n",
        "def softmax(x):\n",
        "    x_stable = x - torch.max(x, dim=1, keepdim=True)[0]\n",
        "    exp_x = torch.exp(x_stable)\n",
        "    return exp_x / torch.sum(exp_x, dim=1, keepdim=True)\n",
        "\n",
        "def cross_entropy_loss(probs, labels):\n",
        "    N = probs.shape[0]\n",
        "    correct_probs = probs[torch.arange(N, device=probs.device), labels]\n",
        "    loss = -torch.log(correct_probs)\n",
        "    return loss.mean()\n",
        "\n",
        "def load_data(csv_path, device):\n",
        "    df = pd.read_csv(csv_path, skiprows=1, low_memory=False, header=None)\n",
        "    data = df.values\n",
        "    labels = data[:, 0].astype(int)\n",
        "    images = data[:, 1:].astype('float32') / 255.0  # Normalize to [0,1]\n",
        "    # Create tensors and then move them to the device\n",
        "    images = torch.tensor(images, dtype=torch.float32).to(device)\n",
        "    labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "pbem-x9rwcTC"
      },
      "id": "pbem-x9rwcTC",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czReDf263IxY",
        "outputId": "a618e26b-de1f-4cfb-9db6-1b51ebb13b01"
      },
      "id": "czReDf263IxY",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "in_features = 784\n",
        "hidden1 = 512\n",
        "hidden2 = 256\n",
        "hidden3 = 128\n",
        "out_features = 10\n",
        "\n",
        "# He initialization for each layer:\n",
        "W1 = torch.randn(in_features, hidden1, dtype=torch.float32, device=device) * math.sqrt(2.0/in_features)\n",
        "b1 = torch.zeros(1, hidden1, dtype=torch.float32, device=device)\n",
        "\n",
        "W2 = torch.randn(hidden1, hidden2, dtype=torch.float32, device=device) * math.sqrt(2.0/hidden1)\n",
        "b2 = torch.zeros(1, hidden2, dtype=torch.float32, device=device)\n",
        "\n",
        "W3 = torch.randn(hidden2, hidden3, dtype=torch.float32, device=device) * math.sqrt(2.0/hidden2)\n",
        "b3 = torch.zeros(1, hidden3, dtype=torch.float32, device=device)\n",
        "\n",
        "W4 = torch.randn(hidden3, out_features, dtype=torch.float32, device=device) * math.sqrt(2.0 / hidden3)\n",
        "b4 = torch.zeros(1, out_features, dtype=torch.float32, device=device)"
      ],
      "metadata": {
        "id": "0yrQlusnRhv7"
      },
      "id": "0yrQlusnRhv7",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_images, train_labels = load_data('mnist_train.csv', device)\n",
        "test_images, test_labels   = load_data('mnist_test.csv', device)\n",
        "\n",
        "#Data to device:\n",
        "train_images = train_images.to(device)\n",
        "train_labels = train_labels.to(device)\n",
        "test_images = test_images.to(device)\n",
        "test_labels = test_labels.to(device)\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.05\n",
        "lambda_l2 = 0.0001\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "num_train = train_images.shape[0]"
      ],
      "metadata": {
        "id": "uqUXoXXguqR-"
      },
      "id": "uqUXoXXguqR-",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    permutation = torch.randperm(num_train, device=device)\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "\n",
        "    for i in range(0, num_train, batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        X = train_images[indices]  # (B, 784)\n",
        "        y = train_labels[indices]  # (B,)\n",
        "        B = X.shape[0]\n",
        "\n",
        "        # Forward Pass\n",
        "        z1 = torch.matmul(X, W1) + b1         # (B, 512)\n",
        "        a1 = relu(z1)\n",
        "\n",
        "        z2 = torch.matmul(a1, W2) + b2          # (B, 256)\n",
        "        a2 = relu(z2)\n",
        "\n",
        "        z3 = torch.matmul(a2, W3) + b3          # (B, 128)\n",
        "        a3 = relu(z3)\n",
        "\n",
        "        logits = torch.matmul(a3, W4) + b4      # (B, 10)\n",
        "        probs = softmax(logits)                # (B, 10)\n",
        "\n",
        "        loss = cross_entropy_loss(probs, y)\n",
        "        # Regularization loss added to cross-entropy loss:\n",
        "        reg_loss = lambda_l2 * (torch.sum(W1**2) + torch.sum(W2**2) + torch.sum(W3**2) + torch.sum(W4**2))\n",
        "        loss_total = loss + reg_loss\n",
        "\n",
        "        # Backward Pass (manual gradients)\n",
        "        one_hot = torch.zeros_like(probs)\n",
        "        one_hot[torch.arange(B, device=device), y] = 1\n",
        "\n",
        "        d_logits = (probs - one_hot) / B  # (B, 10)\n",
        "\n",
        "        dW4 = torch.matmul(a3.t(), d_logits)           # (hidden3, 10)\n",
        "        db4 = d_logits.sum(dim=0, keepdim=True)          # (1, 10)\n",
        "\n",
        "        d_a3 = torch.matmul(d_logits, W4.t())            # (B, hidden3)\n",
        "        d_z3 = d_a3 * relu_derivative(z3)                # (B, hidden3)\n",
        "\n",
        "        dW3 = torch.matmul(a2.t(), d_z3)                 # (hidden2, hidden3)\n",
        "        db3 = d_z3.sum(dim=0, keepdim=True)              # (1, hidden3)\n",
        "\n",
        "        d_a2 = torch.matmul(d_z3, W3.t())                # (B, hidden2)\n",
        "        d_z2 = d_a2 * relu_derivative(z2)                # (B, hidden2)\n",
        "\n",
        "        dW2 = torch.matmul(a1.t(), d_z2)                 # (hidden1, hidden2)\n",
        "        db2 = d_z2.sum(dim=0, keepdim=True)              # (1, hidden2)\n",
        "\n",
        "        d_a1 = torch.matmul(d_z2, W2.t())                # (B, hidden1)\n",
        "        d_z1 = d_a1 * relu_derivative(z1)                # (B, hidden1)\n",
        "\n",
        "        dW1 = torch.matmul(X.t(), d_z1)                  # (in_features, hidden1)\n",
        "        db1 = d_z1.sum(dim=0, keepdim=True)              # (1, hidden1)\n",
        "\n",
        "        # Add regularization gradients: derivative of reg_loss is 2 * lambda_l2 * W\n",
        "        dW1 += 2 * lambda_l2 * W1\n",
        "        dW2 += 2 * lambda_l2 * W2\n",
        "        dW3 += 2 * lambda_l2 * W3\n",
        "        dW4 += 2 * lambda_l2 * W4\n",
        "\n",
        "        # Update Parameters (Gradient Descent)\n",
        "        W1 -= learning_rate * dW1\n",
        "        b1 -= learning_rate * db1\n",
        "        W2 -= learning_rate * dW2\n",
        "        b2 -= learning_rate * db2\n",
        "        W3 -= learning_rate * dW3\n",
        "        b3 -= learning_rate * db3\n",
        "        W4 -= learning_rate * dW4\n",
        "        b4 -= learning_rate * db4\n",
        "\n",
        "        running_loss += loss_total.item() * B\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "        correct_train += (preds == y).sum().item()\n",
        "\n",
        "    train_loss = running_loss / num_train\n",
        "    train_accuracy = 100.0 * correct_train / num_train\n",
        "\n",
        "    # Evaluate on Test Set\n",
        "    z1_test = torch.matmul(test_images, W1) + b1\n",
        "    a1_test = relu(z1_test)\n",
        "    z2_test = torch.matmul(a1_test, W2) + b2\n",
        "    a2_test = relu(z2_test)\n",
        "    z3_test = torch.matmul(a2_test, W3) + b3\n",
        "    a3_test = relu(z3_test)\n",
        "    logits_test = torch.matmul(a3_test, W4) + b4\n",
        "    probs_test = softmax(logits_test)\n",
        "    preds_test = torch.argmax(probs_test, dim=1)\n",
        "    test_accuracy = 100.0 * (preds_test == test_labels).sum().item() / test_labels.shape[0]\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, \" +\n",
        "          f\"Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDrdKni2RuC2",
        "outputId": "7434f0a9-db47-4180-fb3f-85411ef808d3"
      },
      "id": "pDrdKni2RuC2",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss: 0.4507, Train Acc: 91.98%, Test Acc: 96.07%\n",
            "Epoch 2/10: Train Loss: 0.2895, Train Acc: 96.65%, Test Acc: 96.73%\n",
            "Epoch 3/10: Train Loss: 0.2505, Train Acc: 97.76%, Test Acc: 97.34%\n",
            "Epoch 4/10: Train Loss: 0.2258, Train Acc: 98.35%, Test Acc: 97.65%\n",
            "Epoch 5/10: Train Loss: 0.2089, Train Acc: 98.74%, Test Acc: 97.82%\n",
            "Epoch 6/10: Train Loss: 0.1955, Train Acc: 99.09%, Test Acc: 97.92%\n",
            "Epoch 7/10: Train Loss: 0.1831, Train Acc: 99.38%, Test Acc: 97.92%\n",
            "Epoch 8/10: Train Loss: 0.1744, Train Acc: 99.51%, Test Acc: 97.99%\n",
            "Epoch 9/10: Train Loss: 0.1661, Train Acc: 99.66%, Test Acc: 97.95%\n",
            "Epoch 10/10: Train Loss: 0.1591, Train Acc: 99.77%, Test Acc: 98.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xVQz0RN4Bfu"
      },
      "id": "6xVQz0RN4Bfu",
      "execution_count": 141,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}