{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUtd_m-W2sJk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data preparation: FashionMNIST dataset with normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # converts [0,255] to [0,1]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset  = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGwe0ttKqEAi"
      },
      "outputs": [],
      "source": [
        "# 1. Fully Connected Autoencoder (FC-AE)\n",
        "\n",
        "class FCAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FCAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, 1, 28, 28]\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(x.size(0), 1, 28, 28)\n",
        "        return decoded, encoded\n",
        "\n",
        "\n",
        "# 2. Convolutional Autoencoder (CNN-AE)\n",
        "\n",
        "class CNNAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNAutoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "\n",
        "# 3. Sparse Autoencoder (using L1 penalty)\n",
        "\n",
        "class SparseAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SparseAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(x.size(0), 1, 28, 28)\n",
        "        return decoded, encoded\n",
        "\n",
        "# 4. Recurrent Autoencoder (RNN-AE)\n",
        "\n",
        "class RNNAutoencoder(nn.Module):\n",
        "    def __init__(self, hidden_size=128, seq_len=28, input_size=28):\n",
        "        super(RNNAutoencoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len = seq_len\n",
        "        self.encoder_lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.decoder_lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(1)\n",
        "        # Encode with LSTM; we only use the final hidden state\n",
        "        _, (h, _) = self.encoder_lstm(x)  # h: [1, batch, hidden_size]\n",
        "        h = h.squeeze(0)  # [batch, hidden_size]\n",
        "        # Repeat the latent vector for each time step\n",
        "        repeated = h.unsqueeze(1).repeat(1, self.seq_len, 1)  # [batch, 28, hidden_size]\n",
        "        # Decode\n",
        "        decoded_seq, _ = self.decoder_lstm(repeated)\n",
        "        decoded = self.fc(decoded_seq)  # [batch, 28, 28]\n",
        "        # Apply sigmoid and reshape to [batch, 1, 28, 28]\n",
        "        decoded = torch.sigmoid(decoded)\n",
        "        decoded = decoded.unsqueeze(1)\n",
        "        return decoded\n",
        "\n",
        "# 5. Variational Autoencoder (VAE)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim=2):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc_mu = nn.Linear(256, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
        "        self.fc_decode = nn.Linear(latent_dim, 28*28)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        mu = self.fc_mu(h1)\n",
        "        logvar = self.fc_logvar(h1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = torch.sigmoid(self.fc_decode(z))\n",
        "        return h3\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, 1, 28, 28]\n",
        "        x = x.view(x.size(0), -1)\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decode(z)\n",
        "        x_recon = x_recon.view(x.size(0), 1, 28, 28)\n",
        "        return x_recon, mu, logvar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yewN2E8N2vVt"
      },
      "outputs": [],
      "source": [
        "# Training Functions for Each Model\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "def train_model(model, loader, optimizer, criterion, device, extra_loss_fn=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, _ in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # For models that return two outputs (like FC and Sparse AE)\n",
        "        outputs = model(data)\n",
        "        if isinstance(outputs, tuple):\n",
        "            recon = outputs[0]\n",
        "            encoded = outputs[1] if len(outputs) > 1 else None\n",
        "        else:\n",
        "            recon = outputs\n",
        "            encoded = None\n",
        "        loss = criterion(recon, data)\n",
        "        # For Sparse AE: add L1 regularization on the encoded activations\n",
        "        if extra_loss_fn is not None and encoded is not None:\n",
        "            loss = loss + extra_loss_fn(encoded)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "def evaluate_model(model, loader, criterion, device, extra_loss_fn=None):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in loader:\n",
        "            data = data.to(device)\n",
        "            outputs = model(data)\n",
        "            if isinstance(outputs, tuple):\n",
        "                recon = outputs[0]\n",
        "                encoded = outputs[1] if len(outputs) > 1 else None\n",
        "            else:\n",
        "                recon = outputs\n",
        "                encoded = None\n",
        "            loss = criterion(recon, data)\n",
        "            if extra_loss_fn is not None and encoded is not None:\n",
        "                loss = loss + extra_loss_fn(encoded)\n",
        "            running_loss += loss.item() * data.size(0)\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "# Training loop for VAE requires a special loss function\n",
        "def loss_function_vae(recon_x, x, mu, logvar):\n",
        "    # Flatten images\n",
        "    x = x.view(x.size(0), -1)\n",
        "    recon_x = recon_x.view(x.size(0), -1)\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    # KL divergence loss\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uCZI5HXqEAi",
        "outputId": "d1347432-572e-4a27-ce6a-ce200322312a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Fully Connected Autoencoder...\n",
            "Epoch [1/50], Loss: 0.3783\n",
            "Epoch [2/50], Loss: 0.3079\n",
            "Epoch [3/50], Loss: 0.2917\n",
            "Epoch [4/50], Loss: 0.2835\n",
            "Epoch [5/50], Loss: 0.2791\n",
            "Epoch [6/50], Loss: 0.2763\n",
            "Epoch [7/50], Loss: 0.2743\n",
            "Epoch [8/50], Loss: 0.2727\n",
            "Epoch [9/50], Loss: 0.2715\n",
            "Epoch [10/50], Loss: 0.2705\n",
            "Epoch [11/50], Loss: 0.2697\n",
            "Epoch [12/50], Loss: 0.2690\n",
            "Epoch [13/50], Loss: 0.2684\n",
            "Epoch [14/50], Loss: 0.2679\n",
            "Epoch [15/50], Loss: 0.2674\n",
            "Epoch [16/50], Loss: 0.2670\n",
            "Epoch [17/50], Loss: 0.2666\n",
            "Epoch [18/50], Loss: 0.2663\n",
            "Epoch [19/50], Loss: 0.2661\n",
            "Epoch [20/50], Loss: 0.2659\n",
            "Epoch [21/50], Loss: 0.2657\n",
            "Epoch [22/50], Loss: 0.2655\n",
            "Epoch [23/50], Loss: 0.2653\n",
            "Epoch [24/50], Loss: 0.2652\n",
            "Epoch [25/50], Loss: 0.2651\n",
            "Epoch [26/50], Loss: 0.2650\n",
            "Epoch [27/50], Loss: 0.2649\n",
            "Epoch [28/50], Loss: 0.2648\n",
            "Epoch [29/50], Loss: 0.2647\n",
            "Epoch [30/50], Loss: 0.2647\n",
            "Epoch [31/50], Loss: 0.2646\n",
            "Epoch [32/50], Loss: 0.2645\n",
            "Epoch [33/50], Loss: 0.2644\n",
            "Epoch [34/50], Loss: 0.2645\n",
            "Epoch [35/50], Loss: 0.2643\n",
            "Epoch [36/50], Loss: 0.2643\n",
            "Epoch [37/50], Loss: 0.2643\n",
            "Epoch [38/50], Loss: 0.2642\n",
            "Epoch [39/50], Loss: 0.2642\n",
            "Epoch [40/50], Loss: 0.2642\n",
            "Epoch [41/50], Loss: 0.2641\n",
            "Epoch [42/50], Loss: 0.2641\n",
            "Epoch [43/50], Loss: 0.2641\n",
            "Epoch [44/50], Loss: 0.2640\n",
            "Epoch [45/50], Loss: 0.2640\n",
            "Epoch [46/50], Loss: 0.2640\n",
            "Epoch [47/50], Loss: 0.2639\n",
            "Epoch [48/50], Loss: 0.2639\n",
            "Epoch [49/50], Loss: 0.2639\n",
            "Epoch [50/50], Loss: 0.2639\n"
          ]
        }
      ],
      "source": [
        "# 1. Train Fully Connected Autoencoder\n",
        "\n",
        "fc_model = FCAutoencoder().to(device)\n",
        "optimizer_fc = optim.Adam(fc_model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "print(\"Training Fully Connected Autoencoder...\")\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_model(fc_model, train_loader, optimizer_fc, criterion, device)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv6oqJAkqEAj",
        "outputId": "4296c0d9-0e8c-423e-c85b-b4e69b1fc2c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Convolutional Autoencoder...\n",
            "Epoch [1/50], Loss: 0.3293\n",
            "Epoch [2/50], Loss: 0.2790\n",
            "Epoch [3/50], Loss: 0.2737\n",
            "Epoch [4/50], Loss: 0.2707\n",
            "Epoch [5/50], Loss: 0.2687\n",
            "Epoch [6/50], Loss: 0.2673\n",
            "Epoch [7/50], Loss: 0.2661\n",
            "Epoch [8/50], Loss: 0.2651\n",
            "Epoch [9/50], Loss: 0.2641\n",
            "Epoch [10/50], Loss: 0.2633\n",
            "Epoch [11/50], Loss: 0.2626\n",
            "Epoch [12/50], Loss: 0.2619\n",
            "Epoch [13/50], Loss: 0.2614\n",
            "Epoch [14/50], Loss: 0.2609\n",
            "Epoch [15/50], Loss: 0.2604\n",
            "Epoch [16/50], Loss: 0.2599\n",
            "Epoch [17/50], Loss: 0.2595\n",
            "Epoch [18/50], Loss: 0.2591\n",
            "Epoch [19/50], Loss: 0.2588\n",
            "Epoch [20/50], Loss: 0.2584\n",
            "Epoch [21/50], Loss: 0.2582\n",
            "Epoch [22/50], Loss: 0.2579\n",
            "Epoch [23/50], Loss: 0.2577\n",
            "Epoch [24/50], Loss: 0.2575\n",
            "Epoch [25/50], Loss: 0.2573\n",
            "Epoch [26/50], Loss: 0.2571\n",
            "Epoch [27/50], Loss: 0.2569\n",
            "Epoch [28/50], Loss: 0.2568\n",
            "Epoch [29/50], Loss: 0.2566\n",
            "Epoch [30/50], Loss: 0.2564\n",
            "Epoch [31/50], Loss: 0.2563\n",
            "Epoch [32/50], Loss: 0.2562\n",
            "Epoch [33/50], Loss: 0.2560\n",
            "Epoch [34/50], Loss: 0.2559\n",
            "Epoch [35/50], Loss: 0.2558\n",
            "Epoch [36/50], Loss: 0.2557\n",
            "Epoch [37/50], Loss: 0.2556\n",
            "Epoch [38/50], Loss: 0.2555\n",
            "Epoch [39/50], Loss: 0.2554\n",
            "Epoch [40/50], Loss: 0.2553\n",
            "Epoch [41/50], Loss: 0.2552\n",
            "Epoch [42/50], Loss: 0.2551\n",
            "Epoch [43/50], Loss: 0.2551\n",
            "Epoch [44/50], Loss: 0.2550\n",
            "Epoch [45/50], Loss: 0.2549\n",
            "Epoch [46/50], Loss: 0.2548\n",
            "Epoch [47/50], Loss: 0.2548\n",
            "Epoch [48/50], Loss: 0.2547\n",
            "Epoch [49/50], Loss: 0.2546\n",
            "Epoch [50/50], Loss: 0.2546\n"
          ]
        }
      ],
      "source": [
        "# 2. Train Convolutional Autoencoder\n",
        "\n",
        "cnn_model = CNNAutoencoder().to(device)\n",
        "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\nTraining Convolutional Autoencoder...\")\n",
        "for epoch in range(num_epochs):\n",
        "    cnn_model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, _ in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer_cnn.zero_grad()\n",
        "        recon = cnn_model(data)\n",
        "        loss = criterion(recon, data)\n",
        "        loss.backward()\n",
        "        optimizer_cnn.step()\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu10TIiCqEAj",
        "outputId": "0352e3c2-8b40-4039-ad51-9e4b44d71843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Sparse Autoencoder...\n",
            "Epoch [1/50], Loss: 0.3808\n",
            "Epoch [2/50], Loss: 0.3103\n",
            "Epoch [3/50], Loss: 0.2930\n",
            "Epoch [4/50], Loss: 0.2842\n",
            "Epoch [5/50], Loss: 0.2797\n",
            "Epoch [6/50], Loss: 0.2770\n",
            "Epoch [7/50], Loss: 0.2750\n",
            "Epoch [8/50], Loss: 0.2735\n",
            "Epoch [9/50], Loss: 0.2724\n",
            "Epoch [10/50], Loss: 0.2713\n",
            "Epoch [11/50], Loss: 0.2704\n",
            "Epoch [12/50], Loss: 0.2698\n",
            "Epoch [13/50], Loss: 0.2692\n",
            "Epoch [14/50], Loss: 0.2688\n",
            "Epoch [15/50], Loss: 0.2684\n",
            "Epoch [16/50], Loss: 0.2680\n",
            "Epoch [17/50], Loss: 0.2677\n",
            "Epoch [18/50], Loss: 0.2675\n",
            "Epoch [19/50], Loss: 0.2672\n",
            "Epoch [20/50], Loss: 0.2670\n",
            "Epoch [21/50], Loss: 0.2668\n",
            "Epoch [22/50], Loss: 0.2666\n",
            "Epoch [23/50], Loss: 0.2665\n",
            "Epoch [24/50], Loss: 0.2664\n",
            "Epoch [25/50], Loss: 0.2662\n",
            "Epoch [26/50], Loss: 0.2662\n",
            "Epoch [27/50], Loss: 0.2661\n",
            "Epoch [28/50], Loss: 0.2660\n",
            "Epoch [29/50], Loss: 0.2658\n",
            "Epoch [30/50], Loss: 0.2657\n",
            "Epoch [31/50], Loss: 0.2656\n",
            "Epoch [32/50], Loss: 0.2655\n",
            "Epoch [33/50], Loss: 0.2654\n",
            "Epoch [34/50], Loss: 0.2654\n",
            "Epoch [35/50], Loss: 0.2653\n",
            "Epoch [36/50], Loss: 0.2652\n",
            "Epoch [37/50], Loss: 0.2652\n",
            "Epoch [38/50], Loss: 0.2652\n",
            "Epoch [39/50], Loss: 0.2651\n",
            "Epoch [40/50], Loss: 0.2651\n",
            "Epoch [41/50], Loss: 0.2650\n",
            "Epoch [42/50], Loss: 0.2650\n",
            "Epoch [43/50], Loss: 0.2650\n",
            "Epoch [44/50], Loss: 0.2649\n",
            "Epoch [45/50], Loss: 0.2649\n",
            "Epoch [46/50], Loss: 0.2649\n",
            "Epoch [47/50], Loss: 0.2649\n",
            "Epoch [48/50], Loss: 0.2648\n",
            "Epoch [49/50], Loss: 0.2648\n",
            "Epoch [50/50], Loss: 0.2648\n"
          ]
        }
      ],
      "source": [
        "# 3. Train Sparse Autoencoder (with L1 penalty)\n",
        "\n",
        "sparse_model = SparseAutoencoder().to(device)\n",
        "optimizer_sparse = optim.Adam(sparse_model.parameters(), lr=0.001)\n",
        "l1_weight = 1e-4  # regularization strength\n",
        "\n",
        "def l1_penalty(encoded):\n",
        "    return l1_weight * torch.mean(torch.abs(encoded))\n",
        "\n",
        "print(\"\\nTraining Sparse Autoencoder...\")\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_model(sparse_model, train_loader, optimizer_sparse, criterion, device, extra_loss_fn=l1_penalty)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnRF6tsmqEAj",
        "outputId": "8947fd8a-9dfa-4767-cd6c-3fede29d15fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Recurrent Autoencoder...\n",
            "Epoch [1/50], Loss: 0.4509\n",
            "Epoch [2/50], Loss: 0.3584\n",
            "Epoch [3/50], Loss: 0.3372\n",
            "Epoch [4/50], Loss: 0.3228\n",
            "Epoch [5/50], Loss: 0.3142\n",
            "Epoch [6/50], Loss: 0.3090\n",
            "Epoch [7/50], Loss: 0.3051\n",
            "Epoch [8/50], Loss: 0.3009\n",
            "Epoch [9/50], Loss: 0.2988\n",
            "Epoch [10/50], Loss: 0.2965\n",
            "Epoch [11/50], Loss: 0.2943\n",
            "Epoch [12/50], Loss: 0.2930\n",
            "Epoch [13/50], Loss: 0.2900\n",
            "Epoch [14/50], Loss: 0.2891\n",
            "Epoch [15/50], Loss: 0.2873\n",
            "Epoch [16/50], Loss: 0.2861\n",
            "Epoch [17/50], Loss: 0.2851\n",
            "Epoch [18/50], Loss: 0.2839\n",
            "Epoch [19/50], Loss: 0.2824\n",
            "Epoch [20/50], Loss: 0.2824\n",
            "Epoch [21/50], Loss: 0.2802\n",
            "Epoch [22/50], Loss: 0.2803\n",
            "Epoch [23/50], Loss: 0.2798\n",
            "Epoch [24/50], Loss: 0.2784\n",
            "Epoch [25/50], Loss: 0.2780\n",
            "Epoch [26/50], Loss: 0.2773\n",
            "Epoch [27/50], Loss: 0.2769\n",
            "Epoch [28/50], Loss: 0.2762\n",
            "Epoch [29/50], Loss: 0.2759\n",
            "Epoch [30/50], Loss: 0.2750\n",
            "Epoch [31/50], Loss: 0.2743\n",
            "Epoch [32/50], Loss: 0.2743\n",
            "Epoch [33/50], Loss: 0.2737\n",
            "Epoch [34/50], Loss: 0.2733\n",
            "Epoch [35/50], Loss: 0.2724\n",
            "Epoch [36/50], Loss: 0.2724\n",
            "Epoch [37/50], Loss: 0.2724\n",
            "Epoch [38/50], Loss: 0.2711\n",
            "Epoch [39/50], Loss: 0.2717\n",
            "Epoch [40/50], Loss: 0.2708\n",
            "Epoch [41/50], Loss: 0.2702\n",
            "Epoch [42/50], Loss: 0.2702\n",
            "Epoch [43/50], Loss: 0.2699\n",
            "Epoch [44/50], Loss: 0.2698\n",
            "Epoch [45/50], Loss: 0.2694\n",
            "Epoch [46/50], Loss: 0.2688\n",
            "Epoch [47/50], Loss: 0.2686\n",
            "Epoch [48/50], Loss: 0.2685\n",
            "Epoch [49/50], Loss: 0.2682\n",
            "Epoch [50/50], Loss: 0.2679\n"
          ]
        }
      ],
      "source": [
        "# 4. Train Recurrent Autoencoder (RNN-AE)\n",
        "\n",
        "rnn_model = RNNAutoencoder().to(device)\n",
        "optimizer_rnn = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\nTraining Recurrent Autoencoder...\")\n",
        "for epoch in range(num_epochs):\n",
        "    rnn_model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, _ in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer_rnn.zero_grad()\n",
        "        recon = rnn_model(data)\n",
        "        loss = criterion(recon, data)\n",
        "        loss.backward()\n",
        "        optimizer_rnn.step()\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOVPCht9qEAj",
        "outputId": "e69a5d96-45ad-4b08-dcad-993046af2b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Variational Autoencoder...\n",
            "Epoch [1/50], Loss: 517.9469\n",
            "Epoch [2/50], Loss: 411.7731\n",
            "Epoch [3/50], Loss: 376.0749\n",
            "Epoch [4/50], Loss: 344.1278\n",
            "Epoch [5/50], Loss: 330.5324\n",
            "Epoch [6/50], Loss: 324.1010\n",
            "Epoch [7/50], Loss: 319.6928\n",
            "Epoch [8/50], Loss: 316.5633\n",
            "Epoch [9/50], Loss: 313.7584\n",
            "Epoch [10/50], Loss: 311.6252\n",
            "Epoch [11/50], Loss: 309.9167\n",
            "Epoch [12/50], Loss: 308.4353\n",
            "Epoch [13/50], Loss: 307.2347\n",
            "Epoch [14/50], Loss: 306.1952\n",
            "Epoch [15/50], Loss: 305.2491\n",
            "Epoch [16/50], Loss: 304.5440\n",
            "Epoch [17/50], Loss: 303.8156\n",
            "Epoch [18/50], Loss: 303.1402\n",
            "Epoch [19/50], Loss: 302.6240\n",
            "Epoch [20/50], Loss: 302.1980\n",
            "Epoch [21/50], Loss: 301.7688\n",
            "Epoch [22/50], Loss: 301.3899\n",
            "Epoch [23/50], Loss: 301.0634\n",
            "Epoch [24/50], Loss: 300.7734\n",
            "Epoch [25/50], Loss: 300.4966\n",
            "Epoch [26/50], Loss: 300.2126\n",
            "Epoch [27/50], Loss: 299.9921\n",
            "Epoch [28/50], Loss: 299.8062\n",
            "Epoch [29/50], Loss: 299.5748\n",
            "Epoch [30/50], Loss: 299.5009\n",
            "Epoch [31/50], Loss: 299.3087\n",
            "Epoch [32/50], Loss: 299.0673\n",
            "Epoch [33/50], Loss: 299.0084\n",
            "Epoch [34/50], Loss: 298.8752\n",
            "Epoch [35/50], Loss: 298.7126\n",
            "Epoch [36/50], Loss: 298.5817\n",
            "Epoch [37/50], Loss: 298.4858\n",
            "Epoch [38/50], Loss: 298.4149\n",
            "Epoch [39/50], Loss: 298.3169\n",
            "Epoch [40/50], Loss: 298.2315\n",
            "Epoch [41/50], Loss: 298.1394\n",
            "Epoch [42/50], Loss: 298.1030\n",
            "Epoch [43/50], Loss: 298.0218\n",
            "Epoch [44/50], Loss: 297.9231\n",
            "Epoch [45/50], Loss: 297.8677\n",
            "Epoch [46/50], Loss: 297.7915\n",
            "Epoch [47/50], Loss: 297.7712\n",
            "Epoch [48/50], Loss: 297.7482\n",
            "Epoch [49/50], Loss: 297.6245\n",
            "Epoch [50/50], Loss: 297.6080\n"
          ]
        }
      ],
      "source": [
        "# 5. Train Variational Autoencoder (VAE)\n",
        "\n",
        "vae_model = VAE(latent_dim=2).to(device)\n",
        "optimizer_vae = optim.Adam(vae_model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\nTraining Variational Autoencoder...\")\n",
        "vae_model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for data, _ in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer_vae.zero_grad()\n",
        "        recon, mu, logvar = vae_model(data)\n",
        "        loss = loss_function_vae(recon, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer_vae.step()\n",
        "        running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1M_r_iNqEAj",
        "outputId": "d1c918a5-12e3-4245-e79f-5dcad80c98ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x300 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate and Visualize a Sample Reconstruction\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Get a single batch from test set\n",
        "dataiter = iter(test_loader)\n",
        "images, _ = next(dataiter)\n",
        "images = images.to(device)\n",
        "\n",
        "# Get reconstructions from each autoencoder\n",
        "with torch.no_grad():\n",
        "    # FC-AE reconstruction\n",
        "    recon_fc, _ = fc_model(images)\n",
        "    # CNN-AE reconstruction\n",
        "    recon_cnn = cnn_model(images)\n",
        "    # Sparse AE reconstruction\n",
        "    recon_sparse, _ = sparse_model(images)\n",
        "    # RNN-AE reconstruction\n",
        "    recon_rnn = rnn_model(images)\n",
        "    # VAE reconstruction\n",
        "    recon_vae, _, _ = vae_model(images)\n",
        "\n",
        "# Choose the first image from the batch\n",
        "orig_img = images[0].cpu().squeeze().numpy()\n",
        "recon_fc_img = recon_fc[0].cpu().squeeze().numpy()\n",
        "recon_cnn_img = recon_cnn[0].cpu().squeeze().numpy()\n",
        "recon_sparse_img = recon_sparse[0].cpu().squeeze().numpy()\n",
        "recon_rnn_img = recon_rnn[0].cpu().squeeze().numpy()\n",
        "recon_vae_img = recon_vae[0].cpu().squeeze().numpy()\n",
        "\n",
        "# Plot the original and reconstructed images\n",
        "fig, axs = plt.subplots(1, 6, figsize=(15,3))\n",
        "axs[0].imshow(orig_img, cmap='gray')\n",
        "axs[0].set_title('Original')\n",
        "axs[1].imshow(recon_fc_img, cmap='gray')\n",
        "axs[1].set_title('FC-AE')\n",
        "axs[2].imshow(recon_cnn_img, cmap='gray')\n",
        "axs[2].set_title('CNN-AE')\n",
        "axs[3].imshow(recon_sparse_img, cmap='gray')\n",
        "axs[3].set_title('Sparse AE')\n",
        "axs[4].imshow(recon_rnn_img, cmap='gray')\n",
        "axs[4].set_title('RNN-AE')\n",
        "axs[5].imshow(recon_vae_img, cmap='gray')\n",
        "axs[5].set_title('VAE')\n",
        "for ax in axs:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOXPaHS5qEAj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}