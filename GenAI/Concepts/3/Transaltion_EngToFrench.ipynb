{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cznvXaJXSoS",
        "outputId": "2f95bceb-96cd-42e2-8adf-27a664f8ae50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: torchtext==0.15.1 in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.3.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.0.0 torchtext==0.15.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH3wgtDnXpA2",
        "outputId": "6dbd26c8-2c57-414a-945b-fe12805365a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchdata==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchdata==0.6.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchdata==0.6.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKplemy6XvHA",
        "outputId": "1cf78183-8ac6-4fc1-dba0-abf93c4ab89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKMMMtr0X2Ma",
        "outputId": "0eeac4bb-ec6c-496b-ea55-f50586853447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import spacy\n",
        "import math\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "dxA-jjbNygub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download fr_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L84x17jTy5gs",
        "outputId": "c06eaf6b-c1d4-4243-ed27-9ed27fc2a123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from fr-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization using spaCy\n",
        "spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "spacy_fr = spacy.load(\"fr_core_news_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T36IfsdnY0y2",
        "outputId": "2aa912c9-a52a-4a8a-9f0b-b9cb76012d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_fr(text):\n",
        "    return [tok.text.lower() for tok in spacy_fr.tokenizer(text)]\n"
      ],
      "metadata": {
        "id": "YZ3g10IbZHWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_file = \"english.txt\"  # Example: \"english.txt\" in the Colab's root\n",
        "french_file = \"french.txt\"   # Example: \"french.txt\" in the Colab's root"
      ],
      "metadata": {
        "id": "kd78lekPzGDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(english_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    english_sentences = f.read().splitlines()\n",
        "\n",
        "with open(french_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    french_sentences = f.read().splitlines()"
      ],
      "metadata": {
        "id": "VNwMDUXQzKGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary\n",
        "def yield_tokens(sentences, tokenizer):\n",
        "    for sentence in sentences:\n",
        "        yield tokenizer(sentence)\n",
        "\n",
        "vocab_en = build_vocab_from_iterator(yield_tokens(english_sentences, tokenize_en), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "vocab_fr = build_vocab_from_iterator(yield_tokens(french_sentences, tokenize_fr), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "\n",
        "vocab_en.set_default_index(vocab_en[\"<unk>\"])\n",
        "vocab_fr.set_default_index(vocab_fr[\"<unk>\"])"
      ],
      "metadata": {
        "id": "utieOBBNzNPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert sentences to tensor\n",
        "def numericalize(sentence, vocab, tokenizer):\n",
        "    return [vocab[\"<bos>\"]] + [vocab[token] for token in tokenizer(sentence)] + [vocab[\"<eos>\"]]\n"
      ],
      "metadata": {
        "id": "sVBGWonVzPpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, source_sentences, target_sentences, src_vocab, tgt_vocab, src_tokenizer, tgt_tokenizer):\n",
        "        self.source_sentences = source_sentences\n",
        "        self.target_sentences = target_sentences\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.tgt_tokenizer = tgt_tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_tensor = torch.tensor(numericalize(self.source_sentences[idx], self.src_vocab, self.src_tokenizer))\n",
        "        tgt_tensor = torch.tensor(numericalize(self.target_sentences[idx], self.tgt_vocab, self.tgt_tokenizer))\n",
        "        return src_tensor, tgt_tensor"
      ],
      "metadata": {
        "id": "PLvJLfLIzSLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Collate function for padding\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=vocab_en[\"<pad>\"], batch_first=True) # batch_first=True\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=vocab_fr[\"<pad>\"], batch_first=True) # batch_first=True\n",
        "    return src_batch.to(device), tgt_batch.to(device) # Move to device here"
      ],
      "metadata": {
        "id": "61bCGxUrzUyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# DataLoader\n",
        "BATCH_SIZE = 32\n",
        "dataset_en_fr = TranslationDataset(english_sentences, french_sentences, vocab_en, vocab_fr, tokenize_en, tokenize_fr)\n",
        "dataloader_en_fr = DataLoader(dataset_en_fr, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "-1VzMTwzzXNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Model Components\n",
        "class PositionalEncoding(nn.Module): # No variable sequence length\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.pe = self.pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)].to(x.device) # Move pe to the same device as x and use only required length\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "cOEGZYZmzaxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token Embedding\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.embedding.embedding_dim)"
      ],
      "metadata": {
        "id": "p9SHmk6szbmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Modern Transformer with `nn.TransformerEncoder` and `nn.TransformerDecoder`\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, src_lang, tgt_lang, src_vocab_size, tgt_vocab_size, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # move device variable to self\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.src_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.tgt_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones((sz, sz), device=self.device)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "      src_seq_len = src.shape[1]\n",
        "      tgt_seq_len = tgt.shape[1]\n",
        "\n",
        "      tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n",
        "      src_mask = torch.zeros((src_seq_len, src_seq_len),device=self.device).type(torch.bool)\n",
        "\n",
        "      if self.src_lang == \"english\":\n",
        "        src_vocab = vocab_en[\"<pad>\"]\n",
        "      elif self.src_lang == \"french\":\n",
        "        src_vocab = vocab_fr[\"<pad>\"]\n",
        "      else:\n",
        "        print (\"Error: unknown source language selected\")\n",
        "        sys.exit()\n",
        "\n",
        "      if self.tgt_lang == \"english\":\n",
        "        tgt_vocab = vocab_en[\"<pad>\"]\n",
        "      elif self.tgt_lang == \"french\":\n",
        "        tgt_vocab = vocab_fr[\"<pad>\"]\n",
        "      else:\n",
        "        print (\"Error: unknown target language selected\")\n",
        "        sys.exit()\n",
        "\n",
        "      src_padding_mask = (src == src_vocab)\n",
        "      tgt_padding_mask = (tgt == tgt_vocab)\n",
        "      return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, tgt)\n",
        "        src_emb = self.pos_encoder(self.src_embedding(src) * math.sqrt(self.d_model))\n",
        "        tgt_emb = self.pos_encoder(self.tgt_embedding(tgt)  * math.sqrt(self.d_model))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask=src_mask, tgt_mask=tgt_mask, src_key_padding_mask=src_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
        "        return self.fc_out(outs)\n",
        "\n",
        "    def encode(self, src):\n",
        "\n",
        "        src_emb = self.pos_encoder(self.src_embedding(src) * math.sqrt(self.d_model))\n",
        "        src_mask = torch.zeros((src.shape[1], src.shape[1]), device=self.device).type(torch.bool)\n",
        "        return self.transformer.encoder(src_emb, src_mask)\n",
        "\n",
        "    def decode(self, tgt, memory):\n",
        "\n",
        "        tgt_emb = self.pos_encoder(self.tgt_embedding(tgt) * math.sqrt(self.d_model))\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt.shape[1]).to(self.device)\n",
        "        return self.transformer.decoder(tgt_emb, memory, tgt_mask)\n",
        "\n"
      ],
      "metadata": {
        "id": "8NMJ0k_rzeKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "EMB_SIZE = 128\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 256\n",
        "NUM_ENCODER_LAYERS = 2\n",
        "NUM_DECODER_LAYERS = 2\n",
        "model_en_fr = TransformerModel(\"english\", \"french\", len(vocab_en), len(vocab_fr), d_model=EMB_SIZE, nhead=NHEAD, num_encoder_layers=NUM_ENCODER_LAYERS, num_decoder_layers=NUM_DECODER_LAYERS, dim_feedforward=FFN_HID_DIM, dropout=0.1).to(device)\n"
      ],
      "metadata": {
        "id": "2x6zrZ9zzhAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training setup\n",
        "criterion_en_fr = nn.CrossEntropyLoss(ignore_index=vocab_fr[\"<pad>\"])\n",
        "optimizer_en_fr = optim.Adam(model_en_fr.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n"
      ],
      "metadata": {
        "id": "3EBXZAAuzjp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    for src, tgt in dataloader:\n",
        "        # src, tgt = src.to(device), tgt.to(device) # Data is moved to device in the collate_fn\n",
        "        optimizer.zero_grad()\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        output = model(src, tgt_input)  # Teacher forcing, pass source and target (except last token)\n",
        "        loss = criterion(output.reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1)) #compare with target (except first token)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # Gradient clipping\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "4X35U5-_zl63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, epochs=3):\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train_loss = train_epoch(model, dataloader, criterion, optimizer)\n",
        "        val_loss = evaluate(model, dataloader, criterion)\n",
        "        print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(time.time() - epoch_start_time):.3f}s\")\n"
      ],
      "metadata": {
        "id": "qHXMLxeXzsS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            output = model(src, tgt_input)\n",
        "            loss = criterion(output.reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "bKV6s0arzu-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# ------------------------------------\n",
        "# ✅ Improved Greedy Decoding Function\n",
        "def greedy_decode(model, src_tensor, src_vocab, tgt_vocab, max_len=50):\n",
        "    \"\"\"\n",
        "    Decodes a sentence word-by-word using greedy decoding.\n",
        "    - Encodes the source sentence\n",
        "    - Generates one token at a time\n",
        "    - Stops at <eos>\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Encode the source sentence\n",
        "    with torch.no_grad():\n",
        "        memory = model.encode(src_tensor)\n",
        "\n",
        "    # Initialize the target sentence with <bos>\n",
        "    tgt_indices = [tgt_vocab[\"<bos>\"]]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(model.device)  # (1, seq_len)\n",
        "\n",
        "        # Decode using current sequence\n",
        "        with torch.no_grad():\n",
        "            output = model.decode(tgt_tensor, memory)\n",
        "            logits = model.fc_out(output[:, -1, :])  # Get logits for the last token\n",
        "            next_token = logits.argmax(dim=1).item()  # Get the highest probability token\n",
        "\n",
        "        tgt_indices.append(next_token)\n",
        "\n",
        "        # Stop at <eos>\n",
        "        if next_token == tgt_vocab[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    # Convert token indices to words\n",
        "    decoded_sentence = \" \".join([tgt_vocab.get_itos()[idx] for idx in tgt_indices[1:]])  # Skip <bos>\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "XQVXXjcszxPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "train(model_en_fr, dataloader_en_fr, criterion_en_fr, optimizer_en_fr, epochs=EPOCHS)\n",
        "\n",
        "# English to French Conversion\n",
        "def translate_en_to_fr(sentence, model, vocab_en, vocab_fr, tokenize_en):\n",
        "    return greedy_decode(model, torch.tensor(numericalize(sentence, vocab_en, tokenize_en)).unsqueeze(0).to(model.device), vocab_en, vocab_fr)\n",
        "\n",
        "# Testing the model --> English to French\n",
        "print(translate_en_to_fr(\"I am a student.\", model_en_fr, vocab_en, vocab_fr, tokenize_en))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIoOKmNvzznz",
        "outputId": "53489063-5397-4b08-a67d-441c5ecb46b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:544: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
            "  return torch._transformer_encoder_layer_fwd(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1144: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
            "  return torch._native_multi_head_attention(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 4.133, Val loss: 3.060, Epoch time = 149.261s\n",
            "Epoch: 2, Train loss: 2.957, Val loss: 2.445, Epoch time = 148.425s\n",
            "Epoch: 3, Train loss: 2.524, Val loss: 2.118, Epoch time = 149.640s\n",
            "je suis un étudiant . <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear GPU memory to save mem space to start reverse translation model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_fr_en = TransformerModel(\"french\", \"english\", len(vocab_fr), len(vocab_en), d_model=EMB_SIZE, nhead=NHEAD, num_encoder_layers=NUM_ENCODER_LAYERS, num_decoder_layers=NUM_DECODER_LAYERS, dim_feedforward=FFN_HID_DIM, dropout=0.1).to(device)\n",
        "\n",
        "criterion_fr_en = nn.CrossEntropyLoss(ignore_index=vocab_en[\"<pad>\"])\n",
        "optimizer_fr_en = optim.Adam(model_fr_en.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# DataLoader\n",
        "BATCH_SIZE = 32\n",
        "dataset_fr_en = TranslationDataset(french_sentences, english_sentences, vocab_fr, vocab_en, tokenize_fr, tokenize_en)\n",
        "dataloader_fr_en = DataLoader(dataset_fr_en, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "train(model_fr_en, dataloader_fr_en, criterion_fr_en, optimizer_fr_en, epochs=EPOCHS)\n",
        "\n",
        "# English to French Conversion\n",
        "def translate_fr_to_en(sentence, model, vocab_en, vocab_fr, tokenize_en):\n",
        "    return greedy_decode(model, torch.tensor(numericalize(sentence, vocab_fr, tokenize_fr)).unsqueeze(0).to(model.device), vocab_fr, vocab_en)\n",
        "\n",
        "# Testing the model --> English to French\n",
        "print(translate_en_to_fr(\"je suis étudiant .\", model_fr_en, vocab_fr, vocab_en, tokenize_fr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPe-7Oh3Kmag",
        "outputId": "664b26b6-b448-4763-cd49-85f3b2251a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 3.773, Val loss: 2.788, Epoch time = 149.254s\n",
            "Epoch: 2, Train loss: 2.681, Val loss: 2.176, Epoch time = 148.277s\n",
            "Epoch: 3, Train loss: 2.244, Val loss: 1.847, Epoch time = 147.851s\n",
            "i 'm a student . <eos>\n"
          ]
        }
      ]
    }
  ]
}